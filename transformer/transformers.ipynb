{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "ctoi = {c: i for i, c in enumerate(chars)}\n",
    "itoc = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "decoder = lambda x: \"\".join([itoc[i] for i in x])\n",
    "encoder = lambda x: [ctoi[c] for c in x]\n",
    "\n",
    "test_text = \"hello world\"\n",
    "encoding = encoder(test_text)\n",
    "ctoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encoder(text)).long()\n",
    "data.shape, data.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = int(data.shape[0] * 0.9)\n",
    "train_data = data[:training_split]\n",
    "val_data = data[training_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split=\"train\"):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    idxs = torch.randint(0, data.shape[0] - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([data[idx : idx + block_size] for idx in idxs])\n",
    "    y = torch.stack([data[idx + 1 : idx + block_size + 1] for idx in idxs])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "uF&R;g\n",
      "i$.vV-Pe?EMeBeB:NBijsbrD.zvxL,pMj?SFdVyPvxuJRkMtlOsO,Z.wmb'vusoV\n",
      "aQPtud,wwi$stAEF\n",
      "q. vy.yO?av\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "            logits = self.token_embedding(x)\n",
    "        else:\n",
    "            logits = self.token_embedding(x)\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            loss = F.cross_entropy(logits, targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, max_tokens):\n",
    "        for _ in range(max_tokens):\n",
    "            logits, _ = self(x, None)\n",
    "            probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "            next_t = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat((x, next_t), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(len(chars))\n",
    "logits, loss = m(xb, yb)\n",
    "\n",
    "generation = m.generate(torch.tensor([[0]]), 100)\n",
    "print(decoder(generation[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3860368728637695\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "\n",
    "for steps in range(20000):\n",
    "\n",
    "    xb,yb = get_batch()\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Whe ppr, hy, mout j:\n",
      "Maite'dsshe fthenge he t iuglpery, h.\n",
      "Wins t are'd d t as hitt, hiren me oue spo Must fout tharge y wnd, awheder;\n",
      "Of gr gou; thy.\n",
      "NNCHo amas, ar al d thormilys stheses veeensu h Bul CKig.\n",
      "Thert? qupZRGRI'sy, t mereanehen He ard ss ot!und sbeis n bllen vehenshis yoorirvit we-P\n",
      "W:\n",
      "A:\n",
      "R:\n",
      "Thedif ayonofld:\n",
      "I s deverigo begotis t wis:\n",
      "\n",
      "Dandicred, my es arcot;\n",
      "Weo ar;\n",
      "\n",
      "CULordildd cou\n"
     ]
    }
   ],
   "source": [
    "generation = m.generate(torch.tensor([[0]]), 400)\n",
    "print(decoder(generation[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "input = json.loads(\"[0]\")\n",
    "data = torch.tensor(input, dtype=torch.float32)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
