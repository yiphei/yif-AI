# Baseline Transformer

The Baseline Transformer is a canonical decoder-only transformer model, used by many SOTA LLMs like GPT-4. This particular implementation follows the transformer implementation in https://github.com/karpathy/nanoGPT, which faithfully replicates the crux of the Transformer architecture while simplifying other parts. This model serves as the baseline when evaluating new models in this repo.

<div align="center">
  <img src="assets/decoder_diagram.svg" alt="sdasd" width="40%">
</div>