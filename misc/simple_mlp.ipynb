{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../datasets/names/names.txt', 'r').read().splitlines()\n",
    "chars = list(set(''.join(words)))\n",
    "chars.sort()\n",
    "ctoi = {c: i + 1 for i, c in enumerate(chars)}\n",
    "ctoi[\".\"] = 0\n",
    "itoc = {i: c for c, i in ctoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "context_size = 3\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for word in words:\n",
    "    context = [0] * context_size\n",
    "    for char in word:\n",
    "        xs.append(context)\n",
    "        ys.append(ctoi[char])\n",
    "        context = context[1:] + [ctoi[char]]\n",
    "    \n",
    "    xs.append(context)\n",
    "    ys.append(0)\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(xs.shape[0] * 0.8)\n",
    "dev_size = int(xs.shape[0] * 0.1)\n",
    "\n",
    "train_xs = xs[:train_size]\n",
    "train_ys = ys[:train_size]\n",
    "\n",
    "dev_xs = xs[train_size:train_size + dev_size]\n",
    "dev_ys = ys[train_size:train_size + dev_size]\n",
    "\n",
    "test_xs = xs[train_size + dev_size:]\n",
    "test_ys = ys[train_size + dev_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 10), requires_grad=True)\n",
    "W1 = torch.randn((30, 200), requires_grad=True)\n",
    "B1 = torch.randn((200), requires_grad=True)\n",
    "W2 = torch.randn((200, 27), requires_grad=True)\n",
    "B2 = torch.randn((27), requires_grad=True)\n",
    "params = [C, W1, B1, W2, B2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(0, 1 ,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.090450286865234\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "lr_stats = []\n",
    "loss_stats = []\n",
    "for i in range(1000):\n",
    "    #minibatch\n",
    "    mini_batch = torch.randint(0, train_xs.shape[0 ], (300,))\n",
    "\n",
    "    embed = C[train_xs[mini_batch]]\n",
    "    firt_layer_logits = torch.tanh(embed.view(-1,30) @ W1 + B1)\n",
    "    second_layer_logits = firt_layer_logits @ W2 + B2\n",
    "    loss = F.cross_entropy(second_layer_logits, train_ys[mini_batch])\n",
    "    # print(loss.item())\n",
    "\n",
    "    # backward\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # lr = lre[i]\n",
    "    for p in params:\n",
    "        p.data += -0.000001 * p.grad\n",
    "\n",
    "    # lr_stats.append(lr)\n",
    "    loss_stats.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.67305564880371\n"
     ]
    }
   ],
   "source": [
    "embed = C[test_xs]\n",
    "firt_layer_logits = torch.tanh(embed.view(-1,30) @ W1 + B1)\n",
    "second_layer_logits = firt_layer_logits @ W2 + B2\n",
    "loss = F.cross_entropy(second_layer_logits, test_ys)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qhxjrrvvczjhjvacxujvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxmjhrlvijlkuqvxmrhibavxcjvxcjvvczjhjvacxvzrmjyrribbvzehdjlvijnrlvcjekunr.\n",
      "qhxjrrvvczjhjvacxvzrmjmryzr.\n",
      "qhxjrrvvczjhjvxcjvxcjvxmrhaczjhjvxcjvxmjhrlvcnvxmjhrlvcnvxmjhrlvcjekunbvgofunvxmjhrlvcjekunbvgofunvxmjhrlvuqvxmjhrlvcjekunbvxzrhxunbvzehdjjzrhjvacxujvxcjvxcjvxcjvxcjvxcjvvczjhjvacxujvvczjhjvacxujvvczjhjvacxujvxcjvxmrhibaovaovaovaovaovcjekunbvxzrhzgrdyjzehdekvacxvzwfaovcnvxmjhrlvcnvxmrhibaovcnvxmjhrlvczjhjvacxujvxcjvxcjvxurhxunbvxtr.\n",
      "qhxjrrvvczjhjvacxvzwfqwrnzjhjvacxujvxcjvxurhxunr.\n",
      "qhxjurlvknrcwbaovczjhjvacxujvxurhxunbvxzrhxunbvxzrhzr.\n",
      "qhxjurlhujuweaovaovaovaovcnvxmjhrlvuqvxurhxunr.\n",
      "qhxjurlaytxunbvxyrlqujuweaovcjekunbvxcjvxmjhrlvcnvxmjhrlvyqzrrdkjpwvxfzrhzr.\n",
      "qhxjrrvvczjhjvacxvzwfqwrnzjhjvacxujvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxurhxunhxmjhrlvcjekunbvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxmjhrlvijzr.\n",
      "qhxjurlqujuweaovaovaovcjekunbvxoroaoukxxurhxunbvxzrhxunbvgofunr.\n",
      "qhxjurlhujvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxurhxunbvxzrhzgrdwjzwbqyaovcnvxmjhrlvyjzehddwfdjoroaouknmr.\n",
      "qhxjrrvwcjjzrovcjekunbvgofunvxmjhrlvuqvxmjhrlvijnrlvyqzrrdkjzroaoukxmrhibaoaoukxmrhibaoaoukvczjhjvacxujvvczjhjvacxvzwgqwrnzjhjvacxujvxmjhrlvcjekunbvxyrlqujuweaovaovcjekunbvxzrhjvacxvzwfqwrnzjhjvacxvzwbqyazrbqhxjrrvvczjhjvxcjvxcjvxcjvxmrhibaoaoukvczjhjvacxvzwfdjoroaohanfvxfrrvvczjhjvacxvzwfqwrnzjhjvacxvzbgqyrlquqrfvcqzjrzjhjvacxvzwgqwrnzjhjvacxvzwgqwrnzjhjvacxvzrmjyrribbvzehjhrlvknrcvjfmrovcjekunbvxzrhjvacxvzwgqwrnzjhjvacxvzwbqyaovaovcnvxmrhibaoaouknmryzr.\n",
      "qhxjurvvczjhjvacxvzwgqwrnzjhjvxcjvxcjvxcjvxcjvxcjvxmjhrlvuqvxmjhrlvcjekunbvxzrhxunr.\n",
      "qllujhmwfkmffrpxkavxcjvxcjvxcjvxcjvxcjvvczjhjvacxujvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxcjvxmjhrlvijzrovcnvxmrhibaovaovcnvxmrhibaovaovaovaovcjekunbvxyrlqujuweaovcnvxmjhrlvuqvxmjhrlvijzrovcnvxmjhrlvcjekunbvxyrlqujuweaohanlkxjurlhyjzehjhrlvuqvxmrhibaovcjekunbvgczjhjvacxujvxcjvxmjhrlvcjekunbvxoroaovaovaovcnvxmjhrlvcjekunbvxyrlqujuwrovcnvxmjhrlvcjowknfvxfrrlukvccjjzrhzgrdwjzwbqyazrbqhxjrrvvczjhjvacxujvxcjvxcjvxmjhrlvczjhjvxcjvxcjvxcjvxmrhzgrdyjzehdjjgrlvcjekunrcwbaovaovaovanxcjvxcjvxcjvxmjhrlvuqvxmjhrlvcnvxmjhrlvijzr.\n",
      "hlqsjnrlvijzrhxu.\n",
      "qhxjurlhujuwrovcnvxmrhibaovcnvxmjhrlvcjekunbvxyrlqujuweaovaovcjekunr.\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    word = []\n",
    "    idxs = [0] * context_size\n",
    "    while True:\n",
    "        embed = C[torch.tensor([idxs])]\n",
    "        firt_layer_logits = torch.tanh(embed.view(-1,30) @ W1 + B1)\n",
    "        second_layer_logits = firt_layer_logits @ W2 + B2\n",
    "        probs = F.softmax(second_layer_logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        word.append(itoc[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "        idxs = idxs[1:] + [ix]\n",
    "    \n",
    "    print(\"\".join(word))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
