{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.emma.',\n",
       " '.olivia.',\n",
       " '.ava.',\n",
       " '.isabella.',\n",
       " '.sophia.',\n",
       " '.charlotte.',\n",
       " '.mia.',\n",
       " '.amelia.',\n",
       " '.harper.',\n",
       " '.evelyn.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(words)):\n",
    "    words[i] = \".\" + words[i] + \".\"\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(set(''.join(words)))\n",
    "chars.sort()\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctoi = {c:i for i, c in enumerate(chars)}\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itoc = {i:c for c, i in ctoi.items()}\n",
    "itoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13,  ..., 25, 26, 24]),\n",
       " tensor([ 5, 13, 13,  ..., 26, 24,  0]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for word in words:\n",
    "    for char_i, char_j in zip(word, word[1:]):\n",
    "        xs.append(ctoi[char_i])\n",
    "        ys.append(ctoi[char_j])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xsenc = F.one_hot(xs, num_classes=len(ctoi.keys())).float()\n",
    "xsenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674e+00, -2.3729e-01, -2.7385e-02, -1.1008e+00,  2.8588e-01,\n",
       "         -2.9644e-02, -1.5471e+00,  6.0489e-01,  7.9136e-02,  9.0462e-01,\n",
       "         -4.7125e-01,  7.8682e-01, -3.2844e-01, -4.3297e-01,  1.3729e+00,\n",
       "          2.9334e+00,  1.5618e+00, -1.6261e+00,  6.7716e-01, -8.4040e-01,\n",
       "          9.8488e-01, -1.4837e-01, -1.4795e+00,  4.4830e-01, -7.0731e-02,\n",
       "          2.4968e+00,  2.4448e+00],\n",
       "        [-6.7006e-01, -1.2199e+00,  3.0314e-01, -1.0725e+00,  7.2762e-01,\n",
       "          5.1114e-02,  1.3095e+00, -8.0220e-01, -8.5042e-01, -1.8068e+00,\n",
       "          1.2523e+00, -1.2256e+00,  1.2165e+00, -9.6478e-01, -2.3211e-01,\n",
       "         -3.4762e-01,  3.3244e-01, -1.3263e+00,  1.1224e+00,  5.9641e-01,\n",
       "          4.5846e-01,  5.4011e-02, -1.7400e+00,  1.1560e-01,  8.0319e-01,\n",
       "          5.4108e-01, -1.1646e+00],\n",
       "        [ 1.4756e-01, -1.0006e+00,  3.8012e-01,  4.7328e-01, -9.1027e-01,\n",
       "         -7.8305e-01,  1.3506e-01, -2.1161e-01, -1.0406e+00, -1.5367e+00,\n",
       "          9.3743e-01, -8.8303e-01,  1.7457e+00,  2.1346e+00, -8.5614e-01,\n",
       "          5.4082e-01,  6.1690e-01,  1.5160e+00, -1.0447e+00, -6.6414e-01,\n",
       "         -7.2390e-01,  1.7507e+00,  1.7530e-01,  9.9280e-01, -6.2787e-01,\n",
       "          7.7023e-02, -1.1641e+00],\n",
       "        [ 1.2473e+00, -2.7061e-01, -1.3635e+00,  1.3066e+00,  3.2307e-01,\n",
       "          1.0358e+00, -8.6249e-01, -1.2575e+00,  9.4180e-01, -1.3257e+00,\n",
       "          1.4670e-01,  1.6913e-01, -1.5397e+00, -7.2759e-01,  1.1491e+00,\n",
       "         -8.7462e-01, -2.9771e-01, -1.3707e+00,  1.1500e-01, -1.0188e+00,\n",
       "         -8.3777e-01, -2.1057e+00, -2.6044e-01, -1.7149e+00, -3.3787e-01,\n",
       "         -1.8263e+00, -8.3897e-01],\n",
       "        [-1.5723e+00,  4.5795e-01, -5.6533e-01,  5.4281e-01,  1.7549e-01,\n",
       "         -2.2901e+00, -7.0928e-01, -2.9284e-01, -2.1803e+00,  7.9311e-02,\n",
       "          9.0187e-01,  1.2028e+00, -5.6144e-01, -1.3753e-01, -1.3799e-01,\n",
       "         -2.0977e+00, -7.9238e-01,  6.0689e-01, -1.4777e+00, -5.1029e-01,\n",
       "          5.6421e-01,  9.6838e-01, -3.1114e-01, -3.0603e-01, -1.7495e+00,\n",
       "         -1.6335e+00,  3.8761e-01],\n",
       "        [ 4.7236e-01,  1.4830e+00,  3.1748e-01,  1.0588e+00,  2.3982e+00,\n",
       "          4.6827e-01, -6.5650e-01,  6.1662e-01, -6.2198e-01,  5.1007e-01,\n",
       "          1.3563e+00,  2.3445e-01, -4.5585e-01, -1.3132e-03, -5.1161e-01,\n",
       "          5.5570e-01,  4.7458e-01, -1.3867e+00,  1.6229e+00,  1.7197e-01,\n",
       "          9.8846e-01,  5.0657e-01,  1.0198e+00, -1.9062e+00, -4.2753e-01,\n",
       "         -2.1259e+00,  9.6041e-01],\n",
       "        [ 1.2482e+00,  2.5341e-01,  2.8188e+00, -3.3983e-01,  7.0311e-01,\n",
       "          4.0716e-01, -1.9018e-01, -6.9652e-01,  1.7039e+00,  7.4204e-01,\n",
       "          9.7370e-01,  3.0028e-01, -2.8971e-01, -3.1566e-01, -8.7898e-01,\n",
       "          1.0661e-01,  1.8598e+00,  5.5752e-02,  1.2815e+00, -6.3182e-01,\n",
       "         -1.2464e+00,  6.8305e-01, -3.9455e-01,  1.4388e-02,  5.7216e-01,\n",
       "          8.6726e-01,  6.3149e-01],\n",
       "        [-1.2230e+00, -2.1286e-01,  5.0950e-01,  3.2713e-01,  1.9661e+00,\n",
       "         -2.4091e-01, -7.9515e-01,  2.7198e-01, -1.1100e+00, -4.5285e-01,\n",
       "         -4.9578e-01,  1.2648e+00,  1.4625e+00,  1.1199e+00,  9.9539e-01,\n",
       "         -1.2353e+00,  7.3818e-01,  8.1415e-01, -7.3806e-01,  5.6714e-01,\n",
       "         -1.4601e+00, -2.4780e-01,  8.8282e-01, -8.1004e-02, -9.5299e-01,\n",
       "         -4.8838e-01, -7.3712e-01],\n",
       "        [ 7.0609e-01, -1.9295e-01,  1.2348e+00,  3.3308e-01,  1.3283e+00,\n",
       "         -1.0921e+00, -8.3952e-01,  1.9098e-01, -7.1750e-01, -3.8668e-01,\n",
       "         -1.2542e+00,  1.2068e+00, -1.7102e+00, -4.7701e-01, -1.0527e+00,\n",
       "         -1.4367e-01, -2.7737e-01,  1.1634e+00, -6.6910e-01,  6.4918e-01,\n",
       "          5.8243e-01,  1.9264e+00, -3.7846e-01,  7.9577e-03,  5.1068e-01,\n",
       "          7.5927e-01, -1.6086e+00],\n",
       "        [-1.6065e-01,  1.3784e+00, -2.7804e-01,  2.0710e-01,  1.0033e+00,\n",
       "         -5.9772e-01, -3.9771e-01, -1.2801e+00,  9.2445e-02,  1.0526e-01,\n",
       "         -3.9072e-01, -4.0091e-01,  5.6533e-01, -1.5065e+00,  1.2898e+00,\n",
       "         -1.5100e+00,  1.0930e+00,  1.0797e+00, -8.6681e-02,  1.3423e+00,\n",
       "          1.5184e-01,  2.4687e-01,  3.1895e-01, -9.8614e-01, -2.1382e-01,\n",
       "         -6.4308e-02, -8.5528e-01],\n",
       "        [ 1.6113e-01,  4.4925e-01,  8.1827e-01, -8.1628e-01, -3.9243e-01,\n",
       "         -7.4521e-01, -9.4649e-01, -1.5941e-01, -1.5047e+00,  8.4682e-01,\n",
       "         -4.9158e-02,  9.3866e-02, -6.4533e-01,  1.2108e+00, -7.8198e-01,\n",
       "          3.8449e-01, -8.5259e-01,  1.0464e+00, -1.8493e+00,  9.1092e-01,\n",
       "         -9.9360e-01,  6.0195e-01, -1.0890e-01,  5.2587e-01, -9.4046e-01,\n",
       "         -1.2773e-01, -2.5679e-01],\n",
       "        [-1.5437e+00,  3.7950e-01, -1.7705e+00, -1.2085e+00,  9.4773e-01,\n",
       "         -9.1355e-01,  7.1023e-01,  7.9512e-01,  5.7662e-01, -7.3778e-01,\n",
       "         -1.5264e+00,  7.1173e-01,  1.4056e+00, -4.0636e-01, -7.4648e-01,\n",
       "          4.9790e-01,  1.1298e-01, -4.1854e-01,  1.7905e-01,  2.3483e-01,\n",
       "          7.3510e-01, -6.1577e-01,  7.0467e-01,  1.1630e-01,  2.8365e-01,\n",
       "         -2.5043e+00, -5.1931e-01],\n",
       "        [-5.9134e-01, -1.1059e-01,  8.3416e-01, -1.0505e+00,  3.6345e-01,\n",
       "          1.8195e-01, -4.8045e-01,  5.3309e-01,  6.7869e-01, -3.5974e-01,\n",
       "         -1.3270e+00, -8.2526e-01,  6.3614e-01,  1.9110e-01,  7.5476e-01,\n",
       "          4.0538e-01,  2.2565e+00,  1.3655e+00, -5.6192e-01, -3.0423e-01,\n",
       "          2.9894e-01,  1.8784e+00,  5.5958e-01,  1.3388e+00,  4.1606e-01,\n",
       "          6.8491e-01, -1.4790e-01],\n",
       "        [ 1.9359e-01,  1.0532e+00,  6.3393e-01,  2.5786e-01,  9.6408e-01,\n",
       "         -2.4855e-01,  2.4756e-02, -3.0404e-02,  1.5622e+00, -4.4852e-01,\n",
       "         -1.2345e+00,  1.1220e+00, -6.7381e-01,  3.7882e-02, -5.5881e-01,\n",
       "         -8.2709e-01,  8.2253e-01, -7.5100e-01,  9.2778e-01, -1.4849e+00,\n",
       "         -2.1293e-01, -1.1860e+00, -6.6092e-01, -2.3348e-01,  1.5447e+00,\n",
       "          6.0061e-01, -7.0909e-01],\n",
       "        [ 1.9217e+00, -1.8182e-01,  1.5220e+00,  5.4644e-01,  4.0859e-01,\n",
       "         -1.9692e+00, -8.9185e-01,  3.2961e-01, -2.5127e-01,  5.5030e-01,\n",
       "         -7.5171e-01, -6.5783e-03, -6.3108e-01,  1.3431e+00,  3.8010e-02,\n",
       "         -7.1654e-01,  1.7206e+00, -5.2149e-01, -2.3248e-01,  1.0774e+00,\n",
       "         -7.6019e-01,  9.0109e-03, -7.9219e-01,  1.2307e+00, -5.2760e-01,\n",
       "         -1.3207e+00, -7.0654e-01],\n",
       "        [-7.7861e-01,  1.2910e+00, -1.5094e+00,  7.4593e-01,  4.8990e-01,\n",
       "         -1.0034e+00,  9.6407e-01,  2.0990e+00, -3.9870e-01, -7.6635e-01,\n",
       "         -2.1007e+00,  1.2331e+00,  7.7481e-01,  2.4311e-01, -2.1322e-01,\n",
       "         -6.9877e-01,  2.0889e-01, -6.2477e-01, -1.0825e-01, -2.1964e+00,\n",
       "          2.7083e-01,  6.1047e-01, -5.8162e-01, -1.7025e+00, -8.0672e-01,\n",
       "         -2.4174e-01,  1.5490e+00],\n",
       "        [-3.4593e-01,  5.4714e-01,  3.1755e-02,  8.1375e-01,  2.6200e-01,\n",
       "         -6.7101e-01,  2.0656e-02,  7.1300e-01, -4.3997e-02, -5.1944e-01,\n",
       "          1.1241e-01, -3.9770e-01, -2.7829e-01, -1.5364e-01, -2.5424e+00,\n",
       "          2.5033e-01,  1.1056e-01, -2.0366e+00, -9.2735e-01, -6.9350e-01,\n",
       "         -5.2788e-01, -8.7438e-01, -1.0102e+00, -1.0522e+00,  1.2348e+00,\n",
       "          2.5907e-02, -9.6676e-01],\n",
       "        [ 1.0904e+00,  5.3966e-01,  6.6741e-01, -2.2316e+00, -1.1603e+00,\n",
       "         -4.2560e-01,  5.9547e-01, -1.0887e+00,  2.4324e-01, -2.1021e+00,\n",
       "         -2.9289e-01, -7.0682e-01,  9.5190e-01, -1.1583e+00, -1.2844e+00,\n",
       "          1.0193e+00,  1.6851e+00,  8.3422e-01,  1.7113e+00,  4.4456e-01,\n",
       "         -7.1861e-01, -7.0343e-01, -7.1332e-01,  9.9760e-01, -6.1980e-01,\n",
       "          1.9522e+00,  1.4311e-01],\n",
       "        [ 1.8765e-01,  7.5974e-01, -2.6387e-01, -7.3048e-01,  6.1955e-01,\n",
       "          3.5577e-02, -7.6460e-02, -1.2306e+00,  1.3419e+00,  1.1878e+00,\n",
       "         -1.0672e+00, -2.1507e+00,  6.7082e-01,  1.1614e+00, -2.4155e-01,\n",
       "          9.5907e-01,  3.8262e-02,  3.9877e-02, -7.7180e-01,  2.9251e-01,\n",
       "         -6.0606e-01, -1.5136e+00, -2.7143e+00, -4.1164e-01, -1.2273e+00,\n",
       "         -4.1746e-01,  1.5021e+00],\n",
       "        [-6.2849e-01, -4.4247e-01,  5.6885e-01,  1.2803e+00, -5.5397e-01,\n",
       "          1.1179e+00, -6.0053e-01, -5.8619e-01, -2.8277e-01,  5.3390e-01,\n",
       "         -9.9388e-01, -1.6996e+00,  1.8362e+00,  4.2016e-01, -6.8729e-01,\n",
       "         -3.5060e-01,  7.5598e-01, -9.3632e-01, -8.4108e-02, -1.6361e+00,\n",
       "          1.0224e+00,  1.0733e+00, -5.7453e-01,  4.9668e-02,  7.2379e-01,\n",
       "          5.9746e-01,  2.6966e+00],\n",
       "        [ 2.7930e+00, -2.2745e+00, -2.3912e-01,  8.7498e-02,  1.4967e+00,\n",
       "         -5.7016e-01, -5.7248e-01,  1.9909e+00, -7.4416e-01,  7.2960e-01,\n",
       "          6.4083e-01,  1.6075e+00, -8.8810e-01,  2.7359e-01, -1.3257e-01,\n",
       "          1.2710e+00,  1.7234e+00,  1.1180e-01,  2.6952e-01,  1.1835e+00,\n",
       "          1.2575e+00,  1.3969e-01,  4.7259e-01,  7.9025e-01,  1.0811e+00,\n",
       "         -9.1965e-01, -4.0503e-01],\n",
       "        [ 4.5696e-01, -5.4184e-01, -2.3025e+00,  2.0127e+00, -4.6452e-01,\n",
       "         -5.8270e-01,  2.0863e+00, -4.7729e-02, -4.4920e-01,  9.5566e-01,\n",
       "         -1.4708e-01, -1.2532e+00, -1.1850e+00,  3.6583e-01, -1.4049e-01,\n",
       "          3.5252e-01, -5.2400e-01, -6.2845e-01, -9.3792e-01,  1.6772e+00,\n",
       "          3.8554e-03, -7.3685e-01, -9.3514e-01,  1.0465e-01, -4.6464e-01,\n",
       "          1.6676e+00,  1.3931e+00],\n",
       "        [ 6.5398e-01, -2.2449e-01,  1.2831e+00, -9.1787e-01, -3.3916e-01,\n",
       "         -1.8058e+00,  6.0518e-01, -5.6252e-01, -7.8933e-01,  1.2767e+00,\n",
       "         -1.0143e+00,  4.1611e-01, -7.5348e-01,  1.7128e+00, -8.7554e-01,\n",
       "          3.9714e-01,  8.4326e-01,  3.7988e-01, -1.1670e+00,  5.5228e-01,\n",
       "         -1.0279e+00, -3.9554e-01, -7.1410e-01, -8.7456e-02, -3.3361e-01,\n",
       "         -1.8798e-01, -1.2647e+00],\n",
       "        [ 2.0021e+00, -2.3470e-01, -1.3765e+00,  9.3426e-01,  1.0880e+00,\n",
       "          1.9179e-01,  3.0114e-01,  8.9896e-01, -8.4454e-01,  2.3267e-01,\n",
       "         -3.9205e-01, -2.5081e-01,  8.7124e-02,  1.3769e+00, -8.3358e-01,\n",
       "         -8.9400e-01,  1.1744e+00, -6.0779e-01, -1.1493e-01, -7.8077e-01,\n",
       "          1.9660e+00,  6.1175e-01,  3.6039e-01, -1.0274e+00,  1.1495e+00,\n",
       "          4.5111e-01,  6.4420e-01],\n",
       "        [ 2.1635e-01, -7.8731e-01, -3.3005e-01,  3.2877e-01, -1.6332e+00,\n",
       "          1.0807e+00,  3.3638e-01,  1.1536e-01,  3.2834e-01,  5.3447e-02,\n",
       "          1.4224e+00, -8.3957e-01, -2.4956e-01, -8.9778e-01, -8.6583e-01,\n",
       "         -1.0786e+00, -1.8384e-01,  7.1622e-01,  1.8175e-01,  1.1053e+00,\n",
       "          1.7003e+00, -1.6965e-01,  1.6293e-01,  1.3413e+00, -2.6301e-01,\n",
       "         -7.5521e-01,  8.1911e-01],\n",
       "        [ 7.4140e-01, -5.8787e-01, -4.6505e-01,  5.3112e-02,  2.2190e+00,\n",
       "         -3.5158e-01,  3.6381e-01,  2.5769e+00,  1.4544e+00, -6.1003e-01,\n",
       "         -5.9961e-01, -5.8392e-01, -1.8104e-02, -9.5177e-01, -9.6400e-01,\n",
       "         -2.8183e-01,  1.0597e+00, -7.2370e-01,  1.4755e-01, -3.2667e-01,\n",
       "          2.4958e+00,  1.1088e+00, -8.5476e-01,  1.8443e+00, -1.3881e-01,\n",
       "          1.3096e+00, -2.5802e-01],\n",
       "        [ 1.0669e+00,  2.1363e-01, -7.6603e-01, -1.6977e+00, -1.5023e-01,\n",
       "         -5.2150e-01, -6.3730e-01,  2.6214e-01,  7.6541e-03,  1.3067e+00,\n",
       "         -6.3482e-01, -1.1042e-04, -6.6158e-01,  1.4723e-01, -6.6036e-02,\n",
       "          5.2851e-01,  5.7950e-01,  2.1438e-01,  9.2200e-01,  5.2919e-01,\n",
       "          7.7070e-01,  4.2899e-01,  3.4330e-01,  2.0698e+00,  1.3405e+00,\n",
       "         -2.1746e-01,  8.6273e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674e+00, -2.3729e-01, -2.7385e-02, -1.1008e+00,  2.8588e-01,\n",
       "         -2.9644e-02, -1.5471e+00,  6.0489e-01,  7.9136e-02,  9.0462e-01,\n",
       "         -4.7125e-01,  7.8682e-01, -3.2844e-01, -4.3297e-01,  1.3729e+00,\n",
       "          2.9334e+00,  1.5618e+00, -1.6261e+00,  6.7716e-01, -8.4040e-01,\n",
       "          9.8488e-01, -1.4837e-01, -1.4795e+00,  4.4830e-01, -7.0731e-02,\n",
       "          2.4968e+00,  2.4448e+00],\n",
       "        [ 4.7236e-01,  1.4830e+00,  3.1748e-01,  1.0588e+00,  2.3982e+00,\n",
       "          4.6827e-01, -6.5650e-01,  6.1662e-01, -6.2198e-01,  5.1007e-01,\n",
       "          1.3563e+00,  2.3445e-01, -4.5585e-01, -1.3132e-03, -5.1161e-01,\n",
       "          5.5570e-01,  4.7458e-01, -1.3867e+00,  1.6229e+00,  1.7197e-01,\n",
       "          9.8846e-01,  5.0657e-01,  1.0198e+00, -1.9062e+00, -4.2753e-01,\n",
       "         -2.1259e+00,  9.6041e-01],\n",
       "        [ 1.9359e-01,  1.0532e+00,  6.3393e-01,  2.5786e-01,  9.6408e-01,\n",
       "         -2.4855e-01,  2.4756e-02, -3.0404e-02,  1.5622e+00, -4.4852e-01,\n",
       "         -1.2345e+00,  1.1220e+00, -6.7381e-01,  3.7882e-02, -5.5881e-01,\n",
       "         -8.2709e-01,  8.2253e-01, -7.5100e-01,  9.2778e-01, -1.4849e+00,\n",
       "         -2.1293e-01, -1.1860e+00, -6.6092e-01, -2.3348e-01,  1.5447e+00,\n",
       "          6.0061e-01, -7.0909e-01],\n",
       "        [ 1.9359e-01,  1.0532e+00,  6.3393e-01,  2.5786e-01,  9.6408e-01,\n",
       "         -2.4855e-01,  2.4756e-02, -3.0404e-02,  1.5622e+00, -4.4852e-01,\n",
       "         -1.2345e+00,  1.1220e+00, -6.7381e-01,  3.7882e-02, -5.5881e-01,\n",
       "         -8.2709e-01,  8.2253e-01, -7.5100e-01,  9.2778e-01, -1.4849e+00,\n",
       "         -2.1293e-01, -1.1860e+00, -6.6092e-01, -2.3348e-01,  1.5447e+00,\n",
       "          6.0061e-01, -7.0909e-01],\n",
       "        [-6.7006e-01, -1.2199e+00,  3.0314e-01, -1.0725e+00,  7.2762e-01,\n",
       "          5.1114e-02,  1.3095e+00, -8.0220e-01, -8.5042e-01, -1.8068e+00,\n",
       "          1.2523e+00, -1.2256e+00,  1.2165e+00, -9.6478e-01, -2.3211e-01,\n",
       "         -3.4762e-01,  3.3244e-01, -1.3263e+00,  1.1224e+00,  5.9641e-01,\n",
       "          4.5846e-01,  5.4011e-02, -1.7400e+00,  1.1560e-01,  8.0319e-01,\n",
       "          5.4108e-01, -1.1646e+00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xsenc @ W\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
       "         0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
       "         0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459],\n",
       "        [0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
       "         0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
       "         0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472],\n",
       "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
       "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
       "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
       "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
       "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
       "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
       "        [0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
       "         0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
       "         0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7693, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0121,  0.0020,  0.0025,  0.0008,  0.0034, -0.1975,  0.0005,  0.0046,\n",
       "          0.0027,  0.0063,  0.0016,  0.0056,  0.0018,  0.0016,  0.0100,  0.0476,\n",
       "          0.0121,  0.0005,  0.0050,  0.0011,  0.0068,  0.0022,  0.0006,  0.0040,\n",
       "          0.0024,  0.0307,  0.0292],\n",
       "        [-0.1970,  0.0017,  0.0079,  0.0020,  0.0121,  0.0062,  0.0217,  0.0026,\n",
       "          0.0025,  0.0010,  0.0205,  0.0017,  0.0198,  0.0022,  0.0046,  0.0041,\n",
       "          0.0082,  0.0016,  0.0180,  0.0106,  0.0093,  0.0062,  0.0010,  0.0066,\n",
       "          0.0131,  0.0101,  0.0018],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0058,  0.0159,  0.0050,  0.0104,  0.0398,  0.0058,  0.0019,  0.0067,\n",
       "          0.0019,  0.0060,  0.0140,  0.0046,  0.0023, -0.1964,  0.0022,  0.0063,\n",
       "          0.0058,  0.0009,  0.0183,  0.0043,  0.0097,  0.0060,  0.0100,  0.0005,\n",
       "          0.0024,  0.0004,  0.0094],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0125, -0.1705,  0.0194,  0.0133,  0.0270,  0.0080,  0.0105,  0.0100,\n",
       "          0.0490,  0.0066,  0.0030,  0.0316,  0.0052, -0.1893,  0.0059,  0.0045,\n",
       "          0.0234,  0.0049,  0.0260,  0.0023,  0.0083,  0.0031,  0.0053,  0.0081,\n",
       "          0.0482,  0.0187,  0.0051],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758953332901001\n",
      "3.371100664138794\n",
      "3.154043197631836\n",
      "3.020373821258545\n",
      "2.927711248397827\n",
      "2.8604021072387695\n",
      "2.8097290992736816\n",
      "2.7701022624969482\n",
      "2.7380728721618652\n",
      "2.711496591567993\n",
      "2.6890032291412354\n",
      "2.6696884632110596\n",
      "2.65293025970459\n",
      "2.638277292251587\n",
      "2.6253881454467773\n",
      "2.613990545272827\n",
      "2.60386323928833\n",
      "2.5948216915130615\n",
      "2.5867116451263428\n",
      "2.579403877258301\n",
      "2.572789192199707\n",
      "2.5667760372161865\n",
      "2.5612881183624268\n",
      "2.5562589168548584\n",
      "2.551633596420288\n",
      "2.547365665435791\n",
      "2.5434155464172363\n",
      "2.5397486686706543\n",
      "2.5363364219665527\n",
      "2.5331544876098633\n",
      "2.5301806926727295\n",
      "2.5273966789245605\n",
      "2.5247862339019775\n",
      "2.522334575653076\n",
      "2.520029067993164\n",
      "2.517857789993286\n",
      "2.515810489654541\n",
      "2.513878345489502\n",
      "2.512051820755005\n",
      "2.510324001312256\n",
      "2.5086867809295654\n",
      "2.5071349143981934\n",
      "2.5056610107421875\n",
      "2.5042612552642822\n",
      "2.5029289722442627\n",
      "2.5016608238220215\n",
      "2.5004520416259766\n",
      "2.4992988109588623\n",
      "2.498197317123413\n",
      "2.497144937515259\n",
      "2.496137857437134\n",
      "2.495173215866089\n",
      "2.4942493438720703\n",
      "2.49336314201355\n",
      "2.4925124645233154\n",
      "2.491694927215576\n",
      "2.4909095764160156\n",
      "2.4901537895202637\n",
      "2.4894261360168457\n",
      "2.488725423812866\n",
      "2.488049268722534\n",
      "2.4873974323272705\n",
      "2.4867680072784424\n",
      "2.4861602783203125\n",
      "2.4855730533599854\n",
      "2.4850046634674072\n",
      "2.484455108642578\n",
      "2.4839231967926025\n",
      "2.483407735824585\n",
      "2.4829084873199463\n",
      "2.482424259185791\n",
      "2.48195481300354\n",
      "2.481499195098877\n",
      "2.4810571670532227\n",
      "2.4806275367736816\n",
      "2.480210065841675\n",
      "2.479804515838623\n",
      "2.479410409927368\n",
      "2.4790267944335938\n",
      "2.4786534309387207\n",
      "2.478290557861328\n",
      "2.4779367446899414\n",
      "2.4775924682617188\n",
      "2.477257251739502\n",
      "2.4769303798675537\n",
      "2.476611852645874\n",
      "2.4763011932373047\n",
      "2.4759981632232666\n",
      "2.4757025241851807\n",
      "2.475414276123047\n",
      "2.475132703781128\n",
      "2.474858045578003\n",
      "2.4745898246765137\n",
      "2.474327802658081\n",
      "2.474071979522705\n",
      "2.4738218784332275\n",
      "2.4735772609710693\n",
      "2.4733383655548096\n",
      "2.47310471534729\n",
      "2.4728763103485107\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)\n",
    "for k in range(100):\n",
    "    xsenc = F.one_hot(xs, num_classes=len(ctoi.keys())).float()\n",
    "    logits = xsenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "    loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -50 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk.\n",
      "heelcaremayan.\n",
      "brrynade.\n",
      "tosshai.\n",
      "jainn.\n",
      "s.\n",
      "ka.\n",
      "nno.\n",
      "pemavammdis.\n",
      "bn.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    word = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=len(ctoi.keys())).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        word.append(itoc[ix])\n",
    "        if itoc[ix] == '.':\n",
    "            break\n",
    "    \n",
    "    print(\"\".join(word))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
