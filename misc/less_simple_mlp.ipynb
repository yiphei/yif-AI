{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../datasets/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616302\n"
     ]
    }
   ],
   "source": [
    "# Let's train a deeper network\n",
    "# The classes we create here are the same API as nn.Module in PyTorch\n",
    "\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0, 1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "  \n",
    "\n",
    "class Embedding:\n",
    "  def __init__(self, dim_in, dim_out):\n",
    "    self.weight = torch.randn((dim_in, dim_out))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    self.out = self.weight[x]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "class Flatten:\n",
    "  def __init__(self, grouping = None):\n",
    "    self.grouping = grouping\n",
    "\n",
    "  def __call__(self, x):\n",
    "    A,B, C = x.shape\n",
    "    x = x.view(A, B // self.grouping, C * self.grouping)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "  \n",
    "class LinearSequence:\n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "      self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 500 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "grouping = 2\n",
    "model = LinearSequence([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  Flatten(grouping),\n",
    "  Linear(n_embd * grouping, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Flatten(grouping),\n",
    "  Linear(n_hidden * grouping, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Flatten(grouping),\n",
    "  Linear(n_hidden * grouping, n_hidden//10, bias=False), BatchNorm1d(n_hidden//10), Tanh(),\n",
    "  Linear(n_hidden // 10, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size),\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  model.layers[-1].gamma *= 0.1\n",
    "  # all other layers: apply gain\n",
    "  for layer in model.layers[:-2]:\n",
    "    if isinstance(layer, Linear):\n",
    "      layer.weight *= 5/3\n",
    "\n",
    "print(sum(p.nelement() for p in model.parameters())) # number of parameters in total\n",
    "for p in model.parameters():\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/   1000: 3.2728\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 1000\n",
    "batch_size = 16\n",
    "lossi = []\n",
    "IS_DEBUG = False\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  x = model(Xb)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  if IS_DEBUG:\n",
    "    for layer in model.layers:\n",
    "      layer.out.retain_grad()\n",
    "\n",
    "  for p in model.parameters():\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in model.parameters():\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "\n",
    "  if i > 998 and IS_DEBUG:\n",
    "    break # AFTER_DEBUG: would take out obviously to run full optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lossi = torch.tensor(lossi).view(-1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16d9e7fd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_lossi.mean(dim=1, keepdim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.333901882171631\n",
      "val 2.332595109939575\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  x = model(x)\n",
    "  loss = F.cross_entropy(x, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carelix.\n",
      "alyll.\n",
      "khirmr.\n",
      "xrehty.\n",
      "skaassa.\n",
      "jazheen.\n",
      "dperyht.\n",
      "kaqei.\n",
      "nelinia.\n",
      "ceriiv.\n",
      "kalein.\n",
      "dalma.\n",
      "kindeen.\n",
      "tishlin.\n",
      "alian.\n",
      "qiwane.\n",
      "ogijaryxi.\n",
      "jameeni.\n",
      "sayle.\n",
      "deciia.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      x = model(torch.tensor([context]))\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
