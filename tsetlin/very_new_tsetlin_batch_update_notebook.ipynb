{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Working seeds\n",
    "# SEED = 9496461801973866405\n",
    "# SEED = 3158761121381184149\n",
    "# SEED = 4954668783344399908\n",
    "# SEED = 2763762423645165824\n",
    "SEED = 1158604801931000331\n",
    "# SEED = 9578037216575286917\n",
    "\n",
    "#FAILED SEEDS\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "# SEED = None\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "tm.l1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 0, 0, 0, 1],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 1, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 0, 0, 0, 1],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 1, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 1, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.W, tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{2, 5}, {3}, {4, 6}, {1, 3, 6, 7}, {2, 3}],\n",
       " [{0, 1, 3, 4, 6, 7},\n",
       "  {0, 1, 2, 4, 5, 6, 7},\n",
       "  {0, 1, 2, 3, 5, 7},\n",
       "  {0, 2, 4, 5},\n",
       "  {0, 1, 4, 5, 6, 7}])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "zero_Y_row_idxs_per_W_row = []\n",
    "one_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = tm.l1.out[:, i]\n",
    "    \n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 0).squeeze(1).tolist()\n",
    "    zero_Y_row_idxs_per_W_row.append(set(zero_Y_idxs))\n",
    "\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    one_Y_row_idxs_per_W_row.append(set(one_Y_idxs))\n",
    "\n",
    "one_Y_row_idxs_per_W_row, zero_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {2, 5}, 1: {3}, 2: {4, 6}, 3: {1, 3, 6, 7}, 4: {2, 3}},\n",
       " {0: {0, 1, 3, 4, 6, 7},\n",
       "  1: {0, 1, 2, 4, 5, 6, 7},\n",
       "  2: {0, 1, 2, 3, 5, 7},\n",
       "  3: {0, 2, 4, 5},\n",
       "  4: {0, 1, 4, 5, 6, 7}})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_one_Y_row_idxs = set()\n",
    "visited_ones = set()\n",
    "for i,x in enumerate(one_Y_row_idxs_per_W_row):\n",
    "    tuple_x = tuple(x)\n",
    "    if tuple_x not in visited_ones:\n",
    "        visited_ones.add(tuple_x)\n",
    "        unique_one_Y_row_idxs.add(i)\n",
    "\n",
    "\n",
    "one_W_idx_to_one_Y_idxs = {x: one_Y_row_idxs_per_W_row[x] for x in unique_one_Y_row_idxs}\n",
    "tracking = {x: zero_Y_row_idxs_per_W_row[x] for x in unique_one_Y_row_idxs}\n",
    "\n",
    "one_W_idx_to_one_Y_idxs, tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 2, 4, 1]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_one_Y_row_idxs = sorted(one_W_idx_to_one_Y_idxs, key=lambda x: len(one_W_idx_to_one_Y_idxs[x]), reverse=True)\n",
    "sorted_one_Y_row_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([({1, 4, 5, 6, 7}, {0, 2, 3}),\n",
       "  ({1, 2, 3, 5, 7}, {0, 4, 6}),\n",
       "  ({1, 3, 6, 7}, {0, 2, 4, 5})],\n",
       " True)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "from itertools import combinations, chain\n",
    "from collections import deque\n",
    "\n",
    "def generate_subsets(set_elements, subset_size):\n",
    "    return [set(x) for x in list(combinations(set_elements, subset_size))]\n",
    "\n",
    "def generate_powerset(set_elements):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(set_elements)\n",
    "    return [set(x) for x in list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))]\n",
    "\n",
    "\n",
    "q = deque(sorted_one_Y_row_idxs)\n",
    "\n",
    "def funca(depth, max_depth, current_solution, prev_W_row_idx, q):\n",
    "    if depth == max_depth or len(current_solution) == 0 or not q:\n",
    "        return [], len(current_solution) == 0\n",
    "\n",
    "    curr_W_row_idx = prev_W_row_idx\n",
    "    while curr_W_row_idx not in current_solution and q:\n",
    "        curr_W_row_idx = q.popleft()\n",
    "\n",
    "    curr_one_Y_idxs = one_W_idx_to_one_Y_idxs[curr_W_row_idx]\n",
    "    min_zero_Y_idxs_len = math.ceil(len(current_solution[curr_W_row_idx]) / (max_depth - depth))\n",
    "    min_zero_Y_subsets = generate_subsets(current_solution[curr_W_row_idx], min(min_zero_Y_idxs_len, len(current_solution[curr_W_row_idx])))\n",
    "\n",
    "    ordered_min_zero_Y_subsets = []\n",
    "    remaining_q = list(q)\n",
    "    for idx in remaining_q:\n",
    "        one_Y_idx = one_W_idx_to_one_Y_idxs[idx]\n",
    "        if len(one_Y_idx) == min_zero_Y_idxs_len and len(one_Y_idx & curr_one_Y_idxs) == 0 and len(one_Y_idx & current_solution[curr_W_row_idx]) > 0:\n",
    "            ordered_min_zero_Y_subsets.append(one_Y_idx)\n",
    "\n",
    "    for subset in min_zero_Y_subsets:\n",
    "        if subset not in ordered_min_zero_Y_subsets:\n",
    "            ordered_min_zero_Y_subsets.append(subset)\n",
    "\n",
    "    for min_zero_Y_subset in ordered_min_zero_Y_subsets:\n",
    "        remaining_Y_idxs = set(range(tm.l1.full_X.shape[0])) - (min_zero_Y_subset | curr_one_Y_idxs)\n",
    "        remaining_Y_subsets = generate_powerset(remaining_Y_idxs)\n",
    "        remaining_Y_subsets.sort(key=lambda x: len(x), reverse=True)\n",
    "\n",
    "        remaining_Y_subsets_ordered = []\n",
    "        for idx in remaining_q:\n",
    "            one_Y_idx = one_W_idx_to_one_Y_idxs[idx]\n",
    "            if one_Y_idx.issubset(remaining_Y_idxs):\n",
    "                remaining_Y_subsets_ordered.append(one_Y_idx)\n",
    "\n",
    "        for subset in remaining_Y_subsets:\n",
    "            if subset not in remaining_Y_subsets_ordered:\n",
    "                remaining_Y_subsets_ordered.append(subset)\n",
    "\n",
    "        for remaining_Y_subset in remaining_Y_subsets_ordered:\n",
    "            opposite_remaining_Y_subset = remaining_Y_idxs - remaining_Y_subset\n",
    "\n",
    "            #add remaining with the opposite\n",
    "            left_clause = curr_one_Y_idxs | opposite_remaining_Y_subset\n",
    "            right_clause = min_zero_Y_subset | remaining_Y_subset\n",
    "\n",
    "            updated_solution = {}\n",
    "            for k,v in current_solution.items():\n",
    "                one_Y_idxs = one_Y_row_idxs_per_W_row[k]\n",
    "                if one_Y_idxs.issubset(left_clause):\n",
    "                    sub = v - right_clause\n",
    "                    if len(sub) > 0:\n",
    "                        updated_solution[k] = sub\n",
    "                elif one_Y_idxs.issubset(right_clause):\n",
    "                    sub = v - left_clause\n",
    "                    if len(sub) > 0:\n",
    "                        updated_solution[k] = sub\n",
    "                else:\n",
    "                    updated_solution[k] = v\n",
    "\n",
    "            next_layers, solved = funca(depth+1, max_depth, updated_solution, curr_W_row_idx, copy.deepcopy(q))\n",
    "            if solved:\n",
    "                return_layers = next_layers\n",
    "                return_layers.append((left_clause, right_clause))\n",
    "                return return_layers, True\n",
    "            \n",
    "            #add remaining with the curr_clause\n",
    "            left_clause = curr_one_Y_idxs | remaining_Y_subset\n",
    "            right_clause = min_zero_Y_subset | opposite_remaining_Y_subset\n",
    "\n",
    "            updated_solution = {}\n",
    "            for k,v in current_solution.items():\n",
    "                one_Y_idxs = one_Y_row_idxs_per_W_row[k]\n",
    "                if one_Y_idxs.issubset(left_clause):\n",
    "                    sub = v - right_clause\n",
    "                    if len(sub) > 0:\n",
    "                        updated_solution[k] = sub\n",
    "                elif one_Y_idxs.issubset(right_clause):\n",
    "                    sub = v - left_clause\n",
    "                    if len(sub) > 0:\n",
    "                        updated_solution[k] = sub\n",
    "                else:\n",
    "                    updated_solution[k] = v\n",
    "\n",
    "            next_layers, solved = funca(depth+1, max_depth, updated_solution, curr_W_row_idx, copy.deepcopy(q))\n",
    "            if solved:\n",
    "                return_layers = next_layers\n",
    "                return_layers.append((left_clause, right_clause))\n",
    "                return return_layers, True\n",
    "\n",
    "    return [], False\n",
    "\n",
    "cols, solved = funca(0, tm.l1.in_dim, tracking, q.popleft(), q)\n",
    "cols, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_full_X = torch.zeros_like(tm.l1.full_X)\n",
    "for i, col in enumerate(cols):\n",
    "    new_full_X[list(col[0]), i] = 1\n",
    "    new_full_X[list(col[1]), i + tm.l1.in_dim] = 1\n",
    "new_full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_W = torch.zeros_like(tm.l1.W)\n",
    "for row_idx, x in enumerate(one_Y_row_idxs_per_W_row):\n",
    "   for i, col in enumerate(cols):\n",
    "        col_left = col[0]\n",
    "        col_right = col[1]\n",
    "        if x.issubset(col_left):\n",
    "            new_W[row_idx, i] = 1\n",
    "        elif x.issubset(col_right):\n",
    "            new_W[row_idx, i + tm.l1.in_dim] = 1\n",
    "            \n",
    "new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsetlin import TsetlinBase\n",
    "\n",
    "tb = TsetlinBase()\n",
    "y2 = tb.conjunction_mul(new_full_X.unsqueeze(1), new_W)\n",
    "(y2 == tm.l1.out).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
