{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "SEED = 9496461801973866405 # this works\n",
    "# SEED = 3158761121381184149\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "tm.l1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 4, 5, 6, 7],\n",
       " [0, 2, 3, 4, 5, 6, 7],\n",
       " [0, 1, 3, 4, 6, 7],\n",
       " [0, 1, 2, 4, 5, 6],\n",
       " [0, 1, 2, 3, 4, 5, 6]]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "zero_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = tm.l1.out[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 0).squeeze(1).tolist()\n",
    "    zero_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "zero_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [1], [2, 5], [3, 7], [7]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "one_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = tm.l1.out[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    one_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "one_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 1],\n",
       "         [0, 1, 1, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 1, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 0, 0, 0, 1],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 1, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 1, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.W, tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{2, 5}, {1, 3, 7}], [{1}, {3, 7}], [{3}, {7}]],\n",
       " {0: [-1, -1, 1],\n",
       "  1: [-1, 1, 0],\n",
       "  2: [1, 0, 0],\n",
       "  3: [-1, -1, 0],\n",
       "  4: [-1, -1, -1]},\n",
       " {0: {0, 4, 6}, 1: {0, 4, 6}, 2: {0, 4, 6}, 3: {0, 4, 6}, 4: {0, 4, 6}})"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking = {i:set(x) for i, x in enumerate(zero_Y_row_idxs_per_W_row)}\n",
    "solution = {i:[0,0,0] for i in range(len(zero_Y_row_idxs_per_W_row))}\n",
    "\n",
    "def funca():\n",
    "    cols = []\n",
    "    for i in range(tm.l1.in_dim):\n",
    "        one_sets_occurrence_in_zeros = {x:[] for x in tracking.keys()}\n",
    "\n",
    "        for k_1 in tracking.keys():\n",
    "            for k_2 in tracking.keys():\n",
    "                if k_1 != k_2:\n",
    "                    if set(one_Y_row_idxs_per_W_row[k_1]).issubset(tracking[k_2]):\n",
    "                        one_sets_occurrence_in_zeros[k_1].append(k_2)\n",
    "\n",
    "        max_occurrence_row_idx = None\n",
    "        max_occurrence_count = None\n",
    "        count_dict = {k: len(v) for k,v in one_sets_occurrence_in_zeros.items()}\n",
    "        for k,v in count_dict.items():\n",
    "            if max_occurrence_row_idx is None or v > max_occurrence_count or (v == max_occurrence_count and len(one_Y_row_idxs_per_W_row[k]) > len(one_Y_row_idxs_per_W_row[max_occurrence_row_idx])):\n",
    "                max_occurrence_count = v\n",
    "                max_occurrence_row_idx = k\n",
    "\n",
    "        one_rows = set(one_Y_row_idxs_per_W_row[max_occurrence_row_idx])\n",
    "        corresponding_zeroes = tracking[max_occurrence_row_idx]\n",
    "        zero_rows = set().union(*[one_Y_row_idxs_per_W_row[x] for x in one_sets_occurrence_in_zeros[max_occurrence_row_idx]])\n",
    "        \n",
    "        match_col_idx = -1\n",
    "        match_col_side = None\n",
    "        max_zero_rows_intersection = -1\n",
    "        for i, col in enumerate(cols):\n",
    "            # TODO: it doesnt have to be an exact subset, but something that could be made into a subset\n",
    "            if one_rows.issubset(col[0]) and len(corresponding_zeroes & col[0]) == 0:\n",
    "                if match_col_idx == -1 or len(zero_rows & col[1]) > max_zero_rows_intersection:\n",
    "                    match_col_idx = i\n",
    "                    max_zero_rows_intersection = len(zero_rows & col[1])\n",
    "                    match_col_side = 0\n",
    "            # elif one_rows.issubset(col[1]) and len(corresponding_zeroes & col[1]) == 0:\n",
    "            #     if match_col == -1 or len(zero_rows & col[0]) > max_zero_rows_intersection:\n",
    "            #         match_col = i\n",
    "            #         max_zero_rows_intersection = len(zero_rows & col[0])\n",
    "            #         match_one_rows_side = 1\n",
    "\n",
    "        if match_col_idx == -1:\n",
    "            left_side = one_rows\n",
    "            right_side = zero_rows\n",
    "            cols.append([one_rows, zero_rows])\n",
    "            match_col_idx = len(cols) - 1\n",
    "            match_col_side = 0\n",
    "        else:\n",
    "            match_col = cols[match_col_idx]\n",
    "            allowed_zeroes = zero_rows - match_col[match_col_side]\n",
    "            new_zero_rows = match_col[1- match_col_side] | allowed_zeroes\n",
    "            match_col[1- match_col_side] = new_zero_rows\n",
    "\n",
    "            left_side = match_col[0]\n",
    "            right_side = match_col[1]\n",
    "            \n",
    "        remove_ks = []\n",
    "        sides = [left_side, right_side]\n",
    "        for k,v in tracking.items():\n",
    "            one_value = set(one_Y_row_idxs_per_W_row[k])\n",
    "            for i, side in enumerate(sides):\n",
    "                if one_value.issubset(side):\n",
    "                    other_side = sides[1-i]\n",
    "                    sub = v - other_side\n",
    "                    tracking[k] = sub\n",
    "                    solution[k][match_col_idx] += (1 if i == 0 else -1)\n",
    "                    if len(sub) == 0:\n",
    "                        remove_ks.append(k)\n",
    "\n",
    "        for k in remove_ks:\n",
    "            tracking.pop(k)\n",
    "    return cols\n",
    "\n",
    "cols = funca()\n",
    "cols, solution, tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{0, 2, 4, 5, 6}, {1, 3, 7}], [{1, 2, 5}, {0, 3, 4, 6, 7}], [{3}, {7}]],\n",
       " {},\n",
       " {0: [-1, -1, 1],\n",
       "  1: [-1, 1, 0],\n",
       "  2: [1, 1, 0],\n",
       "  3: [-1, -1, 0],\n",
       "  4: [-1, -1, -1]})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_row_idx_to_col_idxs = {}\n",
    "available_rows_per_col = []\n",
    "for col in cols:\n",
    "    all_rows = col[0] | col[1]\n",
    "    remaining_rows = set(range(tm.l1.full_X.shape[0])) - all_rows\n",
    "    available_rows_per_col.append(remaining_rows)\n",
    "\n",
    "\n",
    "for j, x in enumerate(one_Y_row_idxs_per_W_row):\n",
    "    set_x = set(x)\n",
    "    for i, col in enumerate(cols):\n",
    "        for z, col_part in enumerate(col):\n",
    "            if set_x.issubset(col_part):\n",
    "                if j not in one_row_idx_to_col_idxs:\n",
    "                    one_row_idx_to_col_idxs[j] = []\n",
    "                one_row_idx_to_col_idxs[j].append((i,z))\n",
    "\n",
    "col_idx_to_one_row_idxs = {}\n",
    "for k,v in one_row_idx_to_col_idxs.items():\n",
    "    for col_idx in v:\n",
    "        if col_idx not in col_idx_to_one_row_idxs:\n",
    "            col_idx_to_one_row_idxs[col_idx] = []\n",
    "        col_idx_to_one_row_idxs[col_idx].append(k)\n",
    "\n",
    "sorted_col_idxs = sorted(col_idx_to_one_row_idxs, key=lambda x: len(col_idx_to_one_row_idxs[x]), reverse=True)\n",
    "for col_idx in sorted_col_idxs:\n",
    "    one_rows = [x for x in col_idx_to_one_row_idxs[col_idx] if x in tracking]\n",
    "    if one_rows:\n",
    "\n",
    "        zero_intersect = set(range(tm.l1.full_X.shape[0])).intersection(*[tracking[x] for x in one_rows])\n",
    "        zero_intersect_with_available = zero_intersect & available_rows_per_col[col_idx[0]]\n",
    "\n",
    "        available_rows_per_col[col_idx[0]] -= zero_intersect_with_available\n",
    "        col_part = cols[col_idx[0]][1-col_idx[1]]\n",
    "        col_part |= zero_intersect_with_available\n",
    "        remove_ks = []\n",
    "        for k,v in tracking.items():\n",
    "            if k in one_rows:\n",
    "                sub = v - zero_intersect_with_available\n",
    "                tracking[k] = sub\n",
    "                if len(sub) == 0:\n",
    "                    remove_ks.append(k)\n",
    "\n",
    "        for k in remove_ks:\n",
    "            tracking.pop(k)\n",
    "\n",
    "remove_ks = []\n",
    "for k,v in tracking.items():\n",
    "    for i, col in enumerate(cols):\n",
    "        col_remaining_size = tm.l1.full_X.shape[0]-(len(col[0]) + len(col[1]))\n",
    "        one_clause = set(one_Y_row_idxs_per_W_row[k])\n",
    "        if len(one_clause) <= col_remaining_size:\n",
    "            for j, col_part in enumerate(col):\n",
    "                if not one_clause.issubset(col_part) and len(v & col_part) == 0:\n",
    "                    col_part |= one_clause\n",
    "                    col_remaining_size -= len(one_clause)\n",
    "\n",
    "                    opposite_col_part = col[1-j]\n",
    "                    remaining_v = list(v - opposite_col_part)\n",
    "                    remaining_to_add = remaining_v[:min(col_remaining_size, len(remaining_v))]\n",
    "                    remaining_v_size = len(remaining_v) - col_remaining_size\n",
    "                    opposite_col_part |= set(remaining_to_add)\n",
    "                    \n",
    "                    if remaining_v_size > 0:\n",
    "                        tracking[k] = sub\n",
    "                        solution[k][i] += (1 if j == 0 else -1)\n",
    "                    else:\n",
    "                        remove_ks.append(k)\n",
    "                        solution[k][i] += (1 if j == 0 else -1)\n",
    "                    break\n",
    "        \n",
    "        if k in remove_ks:\n",
    "            break\n",
    "\n",
    "for k in remove_ks:\n",
    "    tracking.pop(k)\n",
    "cols, tracking, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0, 2, 4, 5, 6}, {1, 3, 7}],\n",
       " [{1, 2, 5}, {0, 3, 4, 6, 7}],\n",
       " [{3}, {0, 1, 2, 4, 5, 6, 7}]]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cols:\n",
    "    remaining_rows = set(range(tm.l1.full_X.shape[0])) - (col[0] | col[1])\n",
    "    col[1] |= remaining_rows\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_full_X = torch.zeros_like(tm.l1.full_X)\n",
    "for i, col in enumerate(cols):\n",
    "    new_full_X[list(col[0]), i] = 1\n",
    "    new_full_X[list(col[1]), i + tm.l1.in_dim] = 1\n",
    "new_full_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_W = torch.zeros_like(tm.l1.W)\n",
    "for i, x in enumerate(one_Y_row_idxs_per_W_row):\n",
    "    W_row_values = solution[i]\n",
    "    for j, val in enumerate(W_row_values):\n",
    "        if val > 0:\n",
    "            new_W[i, j] = 1\n",
    "        elif val < 0:\n",
    "            new_W[i, j + tm.l1.in_dim] = 1\n",
    "new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsetlin import TsetlinBase\n",
    "\n",
    "tb = TsetlinBase()\n",
    "y2 = tb.conjunction_mul(new_full_X.unsqueeze(1), new_W)\n",
    "y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
