{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}XOR.txt', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "# seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "# random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# print(seed)\n",
    "# random.seed(1320387042447901345)\n",
    "# torch.manual_seed(1320387042447901345)\n",
    "tm = TsetlinMachine(2)\n",
    "\n",
    "for i in range(6):\n",
    "    shuffled_idx = torch.randperm(train_x.shape[0])\n",
    "    shuffled_x = train_x[shuffled_idx]\n",
    "    shuffled_y = train_y[shuffled_idx]\n",
    "\n",
    "    for j, (x, y) in enumerate(zip(shuffled_x, shuffled_y)):\n",
    "        out_1 = tm.forward(x).item()\n",
    "        tm.update(y)\n",
    "        out_2 = tm.forward(x).item()\n",
    "        assert y.item() == out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20, 19,  0,  0],\n",
       "         [20,  0,  0,  0],\n",
       "         [ 0, 19,  0,  0],\n",
       "         [ 0, 20, 20,  0],\n",
       "         [20, 20,  0,  0],\n",
       "         [ 0,  0, 20, 20],\n",
       "         [ 0, 20,  0,  0],\n",
       "         [ 0,  0, 20,  0],\n",
       "         [20, 19,  0,  0],\n",
       "         [ 0,  0, 13, 13]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([[18,  0,  0,  0, 19,  0,  0,  0, 18, 13]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.W,tm.l2.W[:, :tm.l2.W.shape[1]//2],tm.l2.W[:, tm.l2.W.shape[1]//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(train_x, train_y):\n",
    "    out = tm.forward(x).item()\n",
    "    assert y.item() == out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
