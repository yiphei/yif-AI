{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class TsetlinBase:\n",
    "    def conjunctin_mul(self, X, W):\n",
    "        self.X = X\n",
    "        self.twod_X = self.X.unsqueeze(0)\n",
    "        self.X_neg = 1 - self.twod_X\n",
    "        self.full_X = torch.cat((self.twod_X, self.X_neg), dim=1)\n",
    "        self.matrix_X = self.full_X.repeat(W.shape[0], 1)\n",
    "        self.mask = W > 0 # TODO: prob need to compare and choose the clause with the highest weight\n",
    "        self.masked_X = torch.where(self.mask, self.matrix_X, torch.tensor(1))\n",
    "        return torch.prod(self.masked_X, dim=1, keepdim=True).view(1,-1)\n",
    "    \n",
    "    def no_saving_conjunctin_mul(self, X, W):\n",
    "        twod_X = X.unsqueeze(0)\n",
    "        X_neg = 1 - twod_X\n",
    "        full_X = torch.cat((twod_X, X_neg), dim=1)\n",
    "        matrix_X = full_X.repeat(W.shape[0], 1)\n",
    "        mask = W > 0 # TODO: prob need to compare and choose the clause with the highest weight\n",
    "        masked_X = torch.where(mask, matrix_X, torch.tensor(1))\n",
    "        return torch.prod(masked_X, dim=1, keepdim=True).view(1,-1)\n",
    "\n",
    "class TsetlinLayer(TsetlinBase):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        W_pos = torch.randint(0, 2, (out_dim, in_dim,))\n",
    "        W_neg = 1 - W_pos\n",
    "        self.W = torch.cat((W_pos, W_neg), dim=1)\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.conjunctin_mul(X, self.W)\n",
    "        self.out = out.squeeze(0)\n",
    "        return self.out\n",
    "    \n",
    "    def helper(expected_sub_values,update_index, X, update_W, can_flip_value, can_remove):\n",
    "        # TODO: the random choice needs to be dynamic, otherwise if it is a very deep layer, it will be very hard to flip values in the earlier layers\n",
    "        flip_value = random.choice([True, False]) and can_flip_value\n",
    "        negation_index = (update_index + X.shape[1]) % X.shape[1]\n",
    "        if flip_value:\n",
    "            expected_sub_values[update_index] = 1 - expected_sub_values[update_index]\n",
    "            expected_sub_values[negation_index] = 1 - expected_sub_values[negation_index]\n",
    "\n",
    "            #TODO: should i set the weight back to 0, as to descrease the confidence of the new flipped clause?\n",
    "            update_W[update_index] = 0\n",
    "            update_W[negation_index] = 1\n",
    "        else:\n",
    "            remove = random.choice([True, False]) and can_remove\n",
    "            if remove:\n",
    "                update_W[update_index] = 0\n",
    "            else:\n",
    "                # TODO: add \"add new clause\"\n",
    "                update_W[update_index] = 0\n",
    "                update_W[negation_index] = 1\n",
    "\n",
    "    def update(self, y, is_first_layer = False):\n",
    "        can_flip_value = not (is_first_layer or torch.equal(y, self.out))\n",
    "        if can_flip_value:\n",
    "            one_y_indexes = torch.nonzero(y == 1).squeeze()\n",
    "            halves = torch.split(self.W[one_y_indexes], self.W.size(1) // 2, dim=1)\n",
    "            pos_w = halves[0]\n",
    "            neg_w = halves[1]\n",
    "            for w_1 in pos_w:\n",
    "                indices = torch.nonzero(w_1 == 1).squeeze()\n",
    "                if any((w_1[indices] == w_2[indices]).any() for w_2 in neg_w):\n",
    "                    can_flip_value = False\n",
    "                    break\n",
    "\n",
    "        expected_sub_values = torch.copy(self.full_X)\n",
    "        if torch.equal(y, self.out):\n",
    "            self.W[self.W > 0] += 1\n",
    "        else:\n",
    "            if can_flip_value:\n",
    "                one_y_indexes = torch.nonzero((y == 1) | (y != self.out)).squeeze()\n",
    "                update_Ws = self.W[one_y_indexes]\n",
    "\n",
    "                for update_W in update_Ws:\n",
    "                    update_indices = [ i for i, (w, v) in enumerate(zip(update_W, expected_sub_values)) if w > 0 and v == 0]\n",
    "                    for update_index in update_indices:\n",
    "                        self.helper(expected_sub_values,update_index, self.X, update_W, can_flip_value, True)\n",
    "\n",
    "                new_out = self.no_saving_conjunctin_mul(expected_sub_values[: self.X.shape[1]], self.W)\n",
    "                zero_y_indexes = torch.nonzero((y == 0) | (y != new_out)).squeeze()\n",
    "                update_Ws = self.W[zero_y_indexes]\n",
    "                for update_W in update_Ws:\n",
    "                    target_indexes = []\n",
    "                    min_confidence = 0\n",
    "                    for j in range(self.W.shape[1]):\n",
    "                        w_value = update_W[j]\n",
    "                        X_value = expected_sub_values[j]\n",
    "                        if w_value > 0 and X_value == 1:\n",
    "                            if w_value < min_confidence or len(target_indexes) == 0:\n",
    "                                target_indexes = [j]\n",
    "                                min_confidence = w_value\n",
    "                            else:\n",
    "                                target_indexes.append(j)\n",
    "\n",
    "                        update_index = random.choice(target_indexes)\n",
    "                        self.helper(expected_sub_values,update_index, self.X, update_W, can_flip_value, False)\n",
    "            else:\n",
    "                update_y_indexes = torch.nonzero(y != self.out).squeeze()\n",
    "                update_Ws = self.W[update_y_indexes]\n",
    "                for update_W in update_Ws:\n",
    "                    pass\n",
    "        return expected_sub_values\n",
    "\n",
    "class TsetlinMachine:\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        self.l1 = TsetlinLayer(in_dim, 10)\n",
    "        self.l2 = TsetlinLayer(10, 1)\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.l1.forward(X)\n",
    "        X = self.l2.forward(X)\n",
    "        self.out = X.squeeze(0)\n",
    "        return self.out\n",
    "    \n",
    "\n",
    "    def update(self, y):\n",
    "        if y == self.out:\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = TsetlinMachine(2)\n",
    "tm.forward(torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n",
      "tensor([[0, 1]])\n",
      "tensor([[1, 0, 0, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TsetlinBase:\n",
    "    def conjunctin_mul(self, X, W):\n",
    "        self.twod_X = X.unsqueeze(0)\n",
    "        print(self.twod_X)\n",
    "        self.X_neg = 1 - self.twod_X\n",
    "        print(self.X_neg)\n",
    "        self.full_X = torch.cat((self.twod_X, self.X_neg), dim=1)\n",
    "        print(self.full_X)\n",
    "        self.matrix_X = self.full_X.repeat(W.shape[0], 1)\n",
    "        self.mask = W > 0\n",
    "        self.masked_X = torch.where(self.mask, self.matrix_X, torch.tensor(1))\n",
    "        return torch.prod(self.masked_X, dim=1, keepdim=True).view(1,-1)\n",
    "    \n",
    "A = torch.tensor([1, 0])\n",
    "\n",
    "B = torch.tensor([[2, -2, 3, 1],\n",
    "                  [1, 2, -3, 4],\n",
    "                  [-1, 0, 1, 2]])\n",
    "\n",
    "TsetlinBase().conjunctin_mul(A, B).unsqueeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
