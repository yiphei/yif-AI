{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class TsetlinBase:\n",
    "    def conjunctin_mul(self, X, W):\n",
    "        self.X = X\n",
    "        self.twod_X = self.X.unsqueeze(0)\n",
    "        self.X_neg = 1 - self.twod_X\n",
    "        self.full_X = torch.cat((self.twod_X, self.X_neg), dim=1)\n",
    "        self.matrix_X = self.full_X.repeat(W.shape[0], 1)\n",
    "        self.mask = W > 0 # TODO: prob need to compare and choose the clause with the highest weight\n",
    "        self.masked_X = torch.where(self.mask, self.matrix_X, torch.tensor(1))\n",
    "        return torch.prod(self.masked_X, dim=1, keepdim=True).view(1,-1)\n",
    "\n",
    "class TsetlinLayer(TsetlinBase):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        w_pos = torch.randint(0, 2, (out_dim, in_dim,))\n",
    "        w_neg = 1 - w_pos\n",
    "        self.w = torch.cat((w_pos, w_neg), dim=1)\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.conjunctin_mul(X, self.w)\n",
    "        self.out = out.squeeze(0)\n",
    "        return self.out\n",
    "    \n",
    "    def helper(update_index,i, X, new_expected_values, w, flip_value):\n",
    "        pos_index = update_index\n",
    "        if pos_index >= X.shape[1]:\n",
    "            pos_index = pos_index - X.shape[1]\n",
    "        if flip_value:\n",
    "            new_expected_values[pos_index] = 1 - X[pos_index]\n",
    "            #TODO: should i set the weight back to 0, as to descrease the confidence of the new flipped clause?\n",
    "            w[i][update_index] = 1\n",
    "            negation_index = (update_index + X.shape[1]) % w.shape[1]\n",
    "            w[i][negation_index] = 0\n",
    "        else:\n",
    "            w[i][update_index] = 0\n",
    "            negation_index = (update_index + X.shape[1]) % w.shape[1]\n",
    "            w[i][negation_index] = 1\n",
    "\n",
    "    def update(self, y, is_first_layer = False):\n",
    "        flip_value = random.choice([True, False]) and not (is_first_layer or torch.equal(y, self.out))\n",
    "        if flip_value:\n",
    "            one_indexes = torch.nonzero(y == 1).squeeze()\n",
    "            halves = torch.split(self.w[one_indexes], self.w.size(1) // 2, dim=1)\n",
    "            pos_w = halves[0]\n",
    "            neg_w = halves[1]\n",
    "            for w_1 in pos_w:\n",
    "                if any(torch.equal(w_1, w_2) for w_2 in neg_w):\n",
    "                    flip_value = False\n",
    "                    break\n",
    "\n",
    "        expected_sub_values = torch.copy(self.twod_X)\n",
    "\n",
    "        if torch.equal(y, self.out):\n",
    "            self.w[self.w > 0] += 1\n",
    "        else:\n",
    "            for i, expected_output in enumerate(y):\n",
    "                if expected_output == 1:\n",
    "                    for j in range(self.w.shape[1]):\n",
    "                        X_value = self.full_X[j]\n",
    "                        w_value = self.w[i][j]\n",
    "                        if w_value > 0 and X_value != expected_output:\n",
    "                            self.helper(j, i, self.X, expected_sub_values, self.w, flip_value)\n",
    "                else:\n",
    "                    target_indexes = []\n",
    "                    min_confidence = 0\n",
    "                    for j in range(self.w.shape[1]):\n",
    "                        X_value = self.full_X[j]\n",
    "                        w_value = self.w[i][j]\n",
    "                        if w_value > 0 and X_value != expected_output:\n",
    "                            if self.w[i][j] < min_confidence or len(target_indexes) == 0:\n",
    "                                target_indexes = [j]\n",
    "                                min_confidence = self.w[i][j]\n",
    "                            else:\n",
    "                                target_indexes.append(j)\n",
    "\n",
    "                    update_index = random.choice(target_indexes)\n",
    "                    self.helper(update_index, i, self.X, expected_sub_values, self.w, flip_value)\n",
    "\n",
    "        return expected_sub_values\n",
    "\n",
    "class TsetlinMachine:\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        self.l1 = TsetlinLayer(in_dim, 10)\n",
    "        self.l2 = TsetlinLayer(10, 1)\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.l1.forward(X)\n",
    "        X = self.l2.forward(X)\n",
    "        self.out = X.squeeze(0)\n",
    "        return self.out\n",
    "    \n",
    "\n",
    "    def update(self, y):\n",
    "        if y == self.out:\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = TsetlinMachine(2)\n",
    "tm.forward(torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n",
      "tensor([[0, 1]])\n",
      "tensor([[1, 0, 0, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TsetlinBase:\n",
    "    def conjunctin_mul(self, X, W):\n",
    "        self.twod_X = X.unsqueeze(0)\n",
    "        print(self.twod_X)\n",
    "        self.X_neg = 1 - self.twod_X\n",
    "        print(self.X_neg)\n",
    "        self.full_X = torch.cat((self.twod_X, self.X_neg), dim=1)\n",
    "        print(self.full_X)\n",
    "        self.matrix_X = self.full_X.repeat(W.shape[0], 1)\n",
    "        self.mask = W > 0\n",
    "        self.masked_X = torch.where(self.mask, self.matrix_X, torch.tensor(1))\n",
    "        return torch.prod(self.masked_X, dim=1, keepdim=True).view(1,-1)\n",
    "    \n",
    "A = torch.tensor([1, 0])\n",
    "\n",
    "B = torch.tensor([[2, -2, 3, 1],\n",
    "                  [1, 2, -3, 4],\n",
    "                  [-1, 0, 1, 2]])\n",
    "\n",
    "TsetlinBase().conjunctin_mul(A, B).unsqueeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
