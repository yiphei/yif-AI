{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m tm \u001b[39m=\u001b[39m TsetlinMachine(train_x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m out_1 \u001b[39m=\u001b[39m tm\u001b[39m.\u001b[39mforward(train_x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m tm\u001b[39m.\u001b[39;49mupdate_batch(train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m out_2 \u001b[39m=\u001b[39m tm\u001b[39m.\u001b[39mforward(train_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifeiyan/micrograd-yifei/tsetlin/tsetlin_batch_notebook.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mequal(train_y,out_2)\n",
      "File \u001b[0;32m~/micrograd-yifei/tsetlin/tsetlin.py:374\u001b[0m, in \u001b[0;36mTsetlinMachine.update_batch\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_batch\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m    373\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m     updated_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml2\u001b[39m.\u001b[39;49mupdate_batch(y)\n\u001b[1;32m    375\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1\u001b[39m.\u001b[39mupdate_batch(updated_X, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/micrograd-yifei/tsetlin/tsetlin.py:204\u001b[0m, in \u001b[0;36mTsetlinLayer.update_batch\u001b[0;34m(self, Y, is_first_layer)\u001b[0m\n\u001b[1;32m    201\u001b[0m     one_Y_row_idxs_per_W_row\u001b[39m.\u001b[39mappend(\u001b[39mset\u001b[39m(one_Y_idxs))\n\u001b[1;32m    203\u001b[0m update_fnc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_batch_first_layar \u001b[39mif\u001b[39;00m is_first_layer \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_batch_non_first_layer\n\u001b[0;32m--> 204\u001b[0m \u001b[39mreturn\u001b[39;00m update_fnc(one_Y_row_idxs_per_W_row, zero_Y_row_idxs_per_W_row)\n",
      "File \u001b[0;32m~/micrograd-yifei/tsetlin/tsetlin.py:334\u001b[0m, in \u001b[0;36mTsetlinLayer.update_batch_non_first_layer\u001b[0;34m(self, one_Y_row_idxs_per_W_row, zero_Y_row_idxs_per_W_row)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m [], \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    333\u001b[0m cols, solved \u001b[39m=\u001b[39m recursive_helper(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_dim, tracking, q\u001b[39m.\u001b[39mpopleft(), q)\n\u001b[0;32m--> 334\u001b[0m \u001b[39massert\u001b[39;00m solved\n\u001b[1;32m    336\u001b[0m new_W \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW)\n\u001b[1;32m    337\u001b[0m \u001b[39mfor\u001b[39;00m row_idx, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(one_Y_row_idxs_per_W_row):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "SEED = \"85666668775314343\"\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "\n",
    "out_1 = tm.forward(train_x)\n",
    "tm.update_batch(train_y)\n",
    "out_2 = tm.forward(train_x)\n",
    "assert torch.equal(train_y,out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 47, 47, 47,  0,  0],\n",
       "         [ 0,  0,  0, 46,  0, 46],\n",
       "         [ 0,  0, 46, 46,  0,  0],\n",
       "         [47, 47, 47,  0,  0,  0],\n",
       "         [ 0, 47, 47, 47,  0,  0]]),\n",
       " tensor([[0, 0, 0, 0, 0]]),\n",
       " tensor([[ 0, 46, 46,  0, 46]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.W,tm.l2.W[:, :tm.l2.W.shape[1]//2],tm.l2.W[:, tm.l2.W.shape[1]//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tm.forward(train_x)\n",
    "assert torch.equal(train_y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_count = 0\n",
    "for _ in range(1000):\n",
    "    tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "    for i in range(6):\n",
    "        shuffled_idx = torch.randperm(train_x.shape[0])\n",
    "        shuffled_x = train_x[shuffled_idx]\n",
    "        shuffled_y = train_y[shuffled_idx]\n",
    "\n",
    "        for j, (x, y) in enumerate(zip(shuffled_x, shuffled_y)):\n",
    "            out_1 = tm.forward(x.unsqueeze(0))\n",
    "            tm.update(y.unsqueeze(0))\n",
    "            out_2 = tm.forward(x.unsqueeze(0))\n",
    "            assert torch.equal(y.unsqueeze(0), out_2)\n",
    "\n",
    "    out = tm.forward(train_x)\n",
    "    if not torch.equal(train_y, out):\n",
    "        failed_count += 1\n",
    "\n",
    "failed_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
