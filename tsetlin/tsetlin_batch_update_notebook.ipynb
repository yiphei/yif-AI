{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "SEED = 9496461801973866405\n",
    "# SEED = None\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "out_1, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1]]),\n",
       " tensor([[0, 0, 1, 1, 0],\n",
       "         [0, 1, 1, 0, 1],\n",
       "         [1, 1, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 1]]),\n",
       " tensor([[1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 1],\n",
       "         [0, 1, 1, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.randint(0,2, tm.l1.out.size())\n",
    "tm.l1.out, Y, tm.l1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤════════════╤════════════╤════════════╤════════════╤════════════╕\n",
      "│ Column 1   │ Column 2   │ Column 3   │ Column 4   │ Column 5   │ Column 6   │\n",
      "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ []         │ []         │ [3]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [1]        │ [2, 4]     │ [1, 4]     │ [4]        │ [1]        │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [0, 1]     │ [0, 4]     │ []         │ [4]        │ [1]        │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ [4]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ [3]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ []         │ []         │ []         │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ [0]        │ []         │ []         │ [1]        │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [1]        │ [2, 3, 4]  │ [1, 3, 4]  │ [4]        │ [1]        │ [2]        │\n",
      "╘════════════╧════════════╧════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "tabular_W_collisions = [] # these are the necessary ones\n",
    "for i in range(tm.l1.full_X.shape[0]):\n",
    "    W_collisions_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "    row_Y = Y[i]\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in one_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        prod = w_1 * neg_W[one_Y_idxs]\n",
    "        collision_idxs = (prod == 1).nonzero(as_tuple=False)\n",
    "        for row_collision_idx, col_collision_idx in collision_idxs:\n",
    "            neg_col_collision_idx = col_collision_idx + tm.l1.in_dim\n",
    "            if pos_one_Y_idx not in W_collisions_row[col_collision_idx]:\n",
    "                W_collisions_row[col_collision_idx].append(pos_one_Y_idx)\n",
    "            if one_Y_idxs[row_collision_idx] not in W_collisions_row[neg_col_collision_idx]:\n",
    "                W_collisions_row[neg_col_collision_idx].append(one_Y_idxs[row_collision_idx])\n",
    "\n",
    "    tabular_W_collisions.append(W_collisions_row)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(tabular_W_collisions[0]))]\n",
    "print(tabulate(tabular_W_collisions, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [2, 4, 0, 3], [3, 1, 4], [4], [1], [2]]"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "W_deps = [[] for _ in range(tm.l1.W.shape[1])] # these are the necessary ones\n",
    "for i in range(tm.l1.full_X.shape[0]):\n",
    "    row_Y = Y[i]\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in one_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        prod = w_1 * neg_W[one_Y_idxs]\n",
    "        collision_idxs = (prod == 1).nonzero(as_tuple=False)\n",
    "        for row_collision_idx, col_collision_idx in collision_idxs:\n",
    "            neg_col_collision_idx = col_collision_idx + tm.l1.in_dim\n",
    "            if pos_one_Y_idx not in W_deps[col_collision_idx]:\n",
    "                W_deps[col_collision_idx].append(pos_one_Y_idx)\n",
    "            if one_Y_idxs[row_collision_idx] not in W_deps[neg_col_collision_idx]:\n",
    "                W_deps[neg_col_collision_idx].append(one_Y_idxs[row_collision_idx])\n",
    "\n",
    "    tabular_W_collisions.append(W_collisions_row)\n",
    "\n",
    "W_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_deps_full = []\n",
    "# for i, single_x in enumerate(tm.l1.full_X):\n",
    "#     W_collisions_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "#     row_Y = Y[i]\n",
    "#     one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1)\n",
    "#     W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "#     pos_W = W_halves[0]\n",
    "#     neg_W = W_halves[1]\n",
    "#     for pos_one_Y_idx in one_Y_idxs:\n",
    "#         w_1 = pos_W[pos_one_Y_idx]\n",
    "#         for neg_one_Y_idx in one_Y_idxs:\n",
    "#             w_2 = neg_W[neg_one_Y_idx]\n",
    "#             pos_one_W_idxs = torch.nonzero(w_1 == 1).squeeze(1)\n",
    "#             neg_one_W_idxs = torch.nonzero(w_2 == 1).squeeze(1)\n",
    "#             for collision_idx in pos_one_W_idxs:\n",
    "#                 if pos_one_Y_idx.item() not in W_collisions_row[collision_idx.item()]:\n",
    "#                     W_collisions_row[collision_idx.item()].append(pos_one_Y_idx.item())\n",
    "#             for collision_idx in neg_one_W_idxs:\n",
    "#                 if neg_one_Y_idx.item() not in W_collisions_row[collision_idx.item() + tm.l1.in_dim]:\n",
    "#                     W_collisions_row[collision_idx.item() + tm.l1.in_dim].append(neg_one_Y_idx.item())\n",
    "#     W_deps_full.append(W_collisions_row)\n",
    "# W_deps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤═════════════════╤═════════════════╤════════════════════╤════════════════════╤════════════════════╕\n",
      "│ Column 1        │ Column 2        │ Column 3        │ Column 4           │ Column 5           │ Column 6           │\n",
      "╞═════════════════╪═════════════════╪═════════════════╪════════════════════╪════════════════════╪════════════════════╡\n",
      "│ [0, 1, 3, 6]    │ [3, 5, 6, 7]    │ [1, 2, 3, 7]    │ [2, 4, 5, 7]       │ [0, 1, 2, 4]       │ [0, 4, 5, 6]       │\n",
      "├─────────────────┼─────────────────┼─────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ [0, 3, 6, 7]    │ [1, 3, 5, 6]    │ [2, 3]          │ [1, 2, 4, 5]       │ [0, 2, 4, 7]       │ [0, 1, 4, 5, 6, 7] │\n",
      "├─────────────────┼─────────────────┼─────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ [2, 4, 7]       │ [0, 1, 2, 4, 5] │ [0, 4, 6]       │ [0, 1, 3, 5, 6]    │ [3, 6, 7]          │ [1, 2, 3, 5, 7]    │\n",
      "├─────────────────┼─────────────────┼─────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ [1, 2, 3, 4, 7] │ [0, 2, 3, 4, 5] │ [0, 1, 3, 4, 6] │ [0, 5, 6]          │ [1, 6, 7]          │ [2, 5, 7]          │\n",
      "├─────────────────┼─────────────────┼─────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ [0, 7]          │ [1, 5]          │ [2, 6]          │ [1, 2, 3, 4, 5, 6] │ [0, 2, 3, 4, 6, 7] │ [0, 1, 3, 4, 5, 7] │\n",
      "╘═════════════════╧═════════════════╧═════════════════╧════════════════════╧════════════════════╧════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "flip_deps_full = []\n",
    "\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    row_Y = Y[:, i]\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1)\n",
    "    must_be_flipped_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    x_stuff = tm.l1.full_X == 1\n",
    "    for row in range(x_stuff.shape[0]):\n",
    "        for col in range(x_stuff.shape[1]):\n",
    "            if (not x_stuff[row,col] and row in one_Y_idxs) or (x_stuff[row,col] and row not in one_Y_idxs):\n",
    "                must_be_flipped_row[col].append(row)\n",
    "\n",
    "    flip_deps_full.append(must_be_flipped_row)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(flip_deps_full[0]))]\n",
    "print(tabulate(flip_deps_full, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤════════════╤════════════╤════════════╤════════════╤════════════╕\n",
      "│ Column 1   │ Column 2   │ Column 3   │ Column 4   │ Column 5   │ Column 6   │\n",
      "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ [6]        │ [6]        │ [2]        │ [2]        │ [2]        │ [6]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [6, 7]     │ [1, 6]     │ [2]        │ [1, 2]     │ [2, 7]     │ [1, 6, 7]  │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [4, 7]     │ [0, 1, 4]  │ [0, 4]     │ [0, 1, 3]  │ [3, 7]     │ [1, 3, 7]  │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [4, 7]     │ [0, 4]     │ [0, 4]     │ [0]        │ [7]        │ [7]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [7]        │ [1]        │ [2]        │ [1, 2, 3]  │ [2, 3, 7]  │ [1, 3, 7]  │\n",
      "╘════════════╧════════════╧════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "flip_deps = []\n",
    "\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    row_Y = Y[:, i]\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1)\n",
    "    must_be_flipped_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    x_stuff = tm.l1.full_X == 1\n",
    "    for row in range(x_stuff.shape[0]):\n",
    "        for col in range(x_stuff.shape[1]):\n",
    "            if (not x_stuff[row,col] and row in one_Y_idxs):\n",
    "                must_be_flipped_row[col].append(row)\n",
    "\n",
    "    flip_deps.append(must_be_flipped_row)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(flip_deps[0]))]\n",
    "print(tabulate(flip_deps, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤═════════════════╤═════════════════╤═════════════════╤═════════════════╤═════════════════╕\n",
      "│ Column 1        │ Column 2        │ Column 3        │ Column 4        │ Column 5        │ Column 6        │\n",
      "╞═════════════════╪═════════════════╪═════════════════╪═════════════════╪═════════════════╪═════════════════╡\n",
      "│ [2, 6]          │ [2, 6]          │ [2, 6]          │ [2, 6]          │ [2, 6]          │ [2, 6]          │\n",
      "├─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┤\n",
      "│ [1, 2, 6, 7]    │ [1, 2, 6, 7]    │ [1, 2, 6, 7]    │ [1, 2, 6, 7]    │ [1, 2, 6, 7]    │ [1, 2, 6, 7]    │\n",
      "├─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┤\n",
      "│ [0, 1, 3, 4, 7] │ [0, 1, 3, 4, 7] │ [0, 1, 3, 4, 7] │ [0, 1, 3, 4, 7] │ [0, 1, 3, 4, 7] │ [0, 1, 3, 4, 7] │\n",
      "├─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┤\n",
      "│ [0, 4, 7]       │ [0, 4, 7]       │ [0, 4, 7]       │ [0, 4, 7]       │ [0, 4, 7]       │ [0, 4, 7]       │\n",
      "├─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┤\n",
      "│ [1, 2, 3, 7]    │ [1, 2, 3, 7]    │ [1, 2, 3, 7]    │ [1, 2, 3, 7]    │ [1, 2, 3, 7]    │ [1, 2, 3, 7]    │\n",
      "╘═════════════════╧═════════════════╧═════════════════╧═════════════════╧═════════════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "has_to_be_1 = []\n",
    "\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    row_Y = Y[:, i]\n",
    "    one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    has_to_be_1.append([ one_Y_idxs for _ in range(tm.l1.W.shape[1])])\n",
    "headers = [f\"Column {i+1}\" for i in range(len(has_to_be_1[0]))]\n",
    "print(tabulate(has_to_be_1, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [2, 4, 0, 3], [3, 1, 4], [4], [1], [2]]"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7], [0, 1, 4, 6], [0, 2, 4], [1, 2, 3], [2, 7], [1, 3, 7]]"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_count = [set() for _ in range(tm.l1.in_dim * 2)]\n",
    "for i, dep in enumerate(W_deps):\n",
    "    for collision_idx in dep:\n",
    "        flip_count[i].update(flip_deps[collision_idx][i])\n",
    "\n",
    "flip_count = [list(x) for x in flip_count]\n",
    "flip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 4, 5],\n",
       " [0, 2, 4, 0, 2],\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]]))"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "SEED = 9496461801973866405\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "def is_there_conflict(col_idx, row_idx,  chosen_idxs):\n",
    "    neg_col_idx =  (col_idx + tm.l1.in_dim) % (tm.l1.in_dim * 2)\n",
    "    if neg_col_idx in chosen_idxs:\n",
    "        return len(set(has_to_be_1[row_idx][0]) & set(has_to_be_1[row_idx][0])) > 0\n",
    "    return False\n",
    "\n",
    "def func(W_deps):\n",
    "    new_W = torch.zeros_like(tm.l1.W)\n",
    "    selected_W_deps_indices = []\n",
    "    for i in range(len(W_deps)//2):\n",
    "        if len(W_deps[i]) > 0:\n",
    "            selected_index = random.choice([i, i + len(W_deps)//2])\n",
    "            if len(W_deps[i]) > len(W_deps[i + len(W_deps)//2]):\n",
    "                selected_index = i + len(W_deps)//2\n",
    "            elif len(W_deps[i]) < len(W_deps[i + len(W_deps)//2]):\n",
    "                selected_index = i\n",
    "            selected_W_deps_indices.append(selected_index)\n",
    "\n",
    "    cannot_be_changed = [[] for _ in range(new_W.shape[0])]\n",
    "    for index in selected_W_deps_indices:\n",
    "        for row_i in W_deps[index]:\n",
    "            cannot_be_changed[row_i].append(index)\n",
    "    \n",
    "\n",
    "    rows_with_unavailable_cols = [ i for i, row in enumerate(cannot_be_changed) if len(row)> 0]\n",
    "    chosen_idxs = torch.zeros(new_W.shape[0]).tolist()\n",
    "    for row_i in rows_with_unavailable_cols:\n",
    "        cannot_be_changed_cols = cannot_be_changed[row_i]\n",
    "        available_col_idxs = [i for i in range(new_W.shape[1])]\n",
    "        random.shuffle(available_col_idxs)\n",
    "        q = queue.Queue()\n",
    "        for i in available_col_idxs:\n",
    "            q.put(i)        \n",
    "\n",
    "        col_idx = q.get()        \n",
    "        while col_idx in cannot_be_changed_cols or is_there_conflict(col_idx, row_i,chosen_idxs):\n",
    "            q.put(col_idx)\n",
    "            col_idx = q.get()\n",
    "        new_W[row_i, col_idx] = 1\n",
    "        chosen_idxs[row_i] = col_idx\n",
    "    for j, row in enumerate(new_W):\n",
    "        if j not in rows_with_unavailable_cols:\n",
    "            available_col_idxs = [i for i in range(new_W.shape[1])]\n",
    "            random.shuffle(available_col_idxs)\n",
    "            q = queue.Queue()\n",
    "            for x in available_col_idxs:\n",
    "                q.put(x)   \n",
    "            col_idx = q.get()\n",
    "            while is_there_conflict(col_idx, j, chosen_idxs):\n",
    "                q.put(col_idx)\n",
    "                col_idx = q.get()\n",
    "\n",
    "            new_W[j, col_idx] = 1\n",
    "            chosen_idxs[j] = col_idx\n",
    "            \n",
    "            \n",
    "            \n",
    "    return selected_W_deps_indices, chosen_idxs, new_W\n",
    "            \n",
    "\n",
    "selected_W_deps_indices, selected_flip_deps_indices, new_W = func(W_deps)\n",
    "selected_W_deps_indices, selected_flip_deps_indices, new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 1],\n",
       "         [0, 1, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 1, 0, 0],\n",
       "         [1, 1, 0, 1, 1, 0]]),\n",
       " tensor([[1, 0, 0, 0, 1, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 1, 1],\n",
       "         [0, 1, 0, 1, 0, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 0, 1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_full_X = torch.clone(tm.l1.full_X)\n",
    "mask_X = torch.zeros_like(new_full_X)\n",
    "for i, col_indx in enumerate(selected_flip_deps_indices):\n",
    "    X_row_idxs = flip_deps[i][col_indx]\n",
    "    for X_row_idx in X_row_idxs:\n",
    "        mask_X[X_row_idx, col_indx] = 1\n",
    "        neg_index = (col_indx + tm.l1.in_dim) % (tm.l1.in_dim*2)\n",
    "        mask_X[X_row_idx, neg_index] = 1\n",
    "\n",
    "new_full_X[mask_X.bool()] = 1 - new_full_X[mask_X.bool()]\n",
    "mask_X,new_full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsetlin import TsetlinBase\n",
    "\n",
    "tb = TsetlinBase()\n",
    "tb.conjunction_mul(new_full_X.unsqueeze(1), new_W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
