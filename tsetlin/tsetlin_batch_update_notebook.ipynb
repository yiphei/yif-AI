{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 1458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "SEED = 9496461801973866405\n",
    "# SEED = None\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "out_1, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1]]),\n",
       " tensor([[0, 0, 1, 1, 0],\n",
       "         [0, 1, 1, 0, 1],\n",
       "         [1, 1, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 1]]),\n",
       " tensor([[1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 1],\n",
       "         [0, 1, 1, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 1459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.randint(0,2, tm.l1.out.size())\n",
    "tm.l1.out, Y, tm.l1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤════════════╤════════════╤════════════╤════════════╤════════════╕\n",
      "│ Column 1   │ Column 2   │ Column 3   │ Column 4   │ Column 5   │ Column 6   │\n",
      "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ []         │ []         │ [3]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [1]        │ [2, 4]     │ [1, 4]     │ [4]        │ [1]        │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [0, 1]     │ [0, 4]     │ []         │ [4]        │ [1]        │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ [4]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ [3]        │ []         │ []         │ [2]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ []         │ []         │ []         │ []         │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ []         │ [0]        │ []         │ []         │ [1]        │ []         │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [1]        │ [2, 3, 4]  │ [1, 3, 4]  │ [4]        │ [1]        │ [2]        │\n",
      "╘════════════╧════════════╧════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "tabular_W_collisions = [] # these are the necessary ones\n",
    "for i in range(tm.l1.full_X.shape[0]):\n",
    "    row_W_collisions = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "    row_Y = Y[i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in zero_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        prod = w_1 * neg_W[zero_Y_idxs]\n",
    "        collision_idxs = (prod == 1).nonzero(as_tuple=False)\n",
    "        for row_collision_idx, col_collision_idx in collision_idxs:\n",
    "            neg_col_collision_idx = col_collision_idx + tm.l1.in_dim\n",
    "            if pos_one_Y_idx not in row_W_collisions[col_collision_idx]:\n",
    "                row_W_collisions[col_collision_idx].append(pos_one_Y_idx)\n",
    "            if zero_Y_idxs[row_collision_idx] not in row_W_collisions[neg_col_collision_idx]:\n",
    "                row_W_collisions[neg_col_collision_idx].append(zero_Y_idxs[row_collision_idx])\n",
    "\n",
    "    tabular_W_collisions.append(row_W_collisions)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(tabular_W_collisions[0]))]\n",
    "print(tabulate(tabular_W_collisions, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [2, 4, 0, 3], [3, 1, 4], [4], [1], [2]]"
      ]
     },
     "execution_count": 1461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "W_collisions = [[] for _ in range(tm.l1.W.shape[1])] # these are the necessary ones\n",
    "for i in range(tm.l1.full_X.shape[0]):\n",
    "    row_Y = Y[i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in zero_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        prod = w_1 * neg_W[zero_Y_idxs]\n",
    "        collision_idxs = (prod == 1).nonzero(as_tuple=False)\n",
    "        for row_collision_idx, col_collision_idx in collision_idxs:\n",
    "            neg_col_collision_idx = col_collision_idx + tm.l1.in_dim\n",
    "            if pos_one_Y_idx not in W_collisions[col_collision_idx]:\n",
    "                W_collisions[col_collision_idx].append(pos_one_Y_idx)\n",
    "            if zero_Y_idxs[row_collision_idx] not in W_collisions[neg_col_collision_idx]:\n",
    "                W_collisions[neg_col_collision_idx].append(zero_Y_idxs[row_collision_idx])\n",
    "\n",
    "W_collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_deps_full = []\n",
    "# for i, single_x in enumerate(tm.l1.full_X):\n",
    "#     W_collisions_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "#     row_Y = Y[i]\n",
    "#     one_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1)\n",
    "#     W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "#     pos_W = W_halves[0]\n",
    "#     neg_W = W_halves[1]\n",
    "#     for pos_one_Y_idx in one_Y_idxs:\n",
    "#         w_1 = pos_W[pos_one_Y_idx]\n",
    "#         for neg_one_Y_idx in one_Y_idxs:\n",
    "#             w_2 = neg_W[neg_one_Y_idx]\n",
    "#             pos_one_W_idxs = torch.nonzero(w_1 == 1).squeeze(1)\n",
    "#             neg_one_W_idxs = torch.nonzero(w_2 == 1).squeeze(1)\n",
    "#             for collision_idx in pos_one_W_idxs:\n",
    "#                 if pos_one_Y_idx.item() not in W_collisions_row[collision_idx.item()]:\n",
    "#                     W_collisions_row[collision_idx.item()].append(pos_one_Y_idx.item())\n",
    "#             for collision_idx in neg_one_W_idxs:\n",
    "#                 if neg_one_Y_idx.item() not in W_collisions_row[collision_idx.item() + tm.l1.in_dim]:\n",
    "#                     W_collisions_row[collision_idx.item() + tm.l1.in_dim].append(neg_one_Y_idx.item())\n",
    "#     W_deps_full.append(W_collisions_row)\n",
    "# W_deps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 1463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════════════════════════════════════════════╤═════════════════════════════════════════════════════════════════╤═════════════════════════════════════════════════════════════════╤═════════════════════════════════════════════════════════════════════════════╤═════════════════════════════════════════════════════════════════════════════╤═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Column 1                                                        │ Column 2                                                        │ Column 3                                                        │ Column 4                                                                    │ Column 5                                                                    │ Column 6                                                                    │\n",
      "╞═════════════════════════════════════════════════════════════════╪═════════════════════════════════════════════════════════════════╪═════════════════════════════════════════════════════════════════╪═════════════════════════════════════════════════════════════════════════════╪═════════════════════════════════════════════════════════════════════════════╪═════════════════════════════════════════════════════════════════════════════╡\n",
      "│ [(0, 'zero'), (1, 'zero'), (3, 'zero'), (6, 'one')]             │ [(3, 'zero'), (5, 'zero'), (6, 'one'), (7, 'zero')]             │ [(1, 'zero'), (2, 'one'), (3, 'zero'), (7, 'zero')]             │ [(2, 'one'), (4, 'zero'), (5, 'zero'), (7, 'zero')]                         │ [(0, 'zero'), (1, 'zero'), (2, 'one'), (4, 'zero')]                         │ [(0, 'zero'), (4, 'zero'), (5, 'zero'), (6, 'one')]                         │\n",
      "├─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ [(0, 'zero'), (3, 'zero'), (6, 'one'), (7, 'one')]              │ [(1, 'one'), (3, 'zero'), (5, 'zero'), (6, 'one')]              │ [(2, 'one'), (3, 'zero')]                                       │ [(1, 'one'), (2, 'one'), (4, 'zero'), (5, 'zero')]                          │ [(0, 'zero'), (2, 'one'), (4, 'zero'), (7, 'one')]                          │ [(0, 'zero'), (1, 'one'), (4, 'zero'), (5, 'zero'), (6, 'one'), (7, 'one')] │\n",
      "├─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ [(2, 'zero'), (4, 'one'), (7, 'one')]                           │ [(0, 'one'), (1, 'one'), (2, 'zero'), (4, 'one'), (5, 'zero')]  │ [(0, 'one'), (4, 'one'), (6, 'zero')]                           │ [(0, 'one'), (1, 'one'), (3, 'one'), (5, 'zero'), (6, 'zero')]              │ [(3, 'one'), (6, 'zero'), (7, 'one')]                                       │ [(1, 'one'), (2, 'zero'), (3, 'one'), (5, 'zero'), (7, 'one')]              │\n",
      "├─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ [(1, 'zero'), (2, 'zero'), (3, 'zero'), (4, 'one'), (7, 'one')] │ [(0, 'one'), (2, 'zero'), (3, 'zero'), (4, 'one'), (5, 'zero')] │ [(0, 'one'), (1, 'zero'), (3, 'zero'), (4, 'one'), (6, 'zero')] │ [(0, 'one'), (5, 'zero'), (6, 'zero')]                                      │ [(1, 'zero'), (6, 'zero'), (7, 'one')]                                      │ [(2, 'zero'), (5, 'zero'), (7, 'one')]                                      │\n",
      "├─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│ [(0, 'zero'), (7, 'one')]                                       │ [(1, 'one'), (5, 'zero')]                                       │ [(2, 'one'), (6, 'zero')]                                       │ [(1, 'one'), (2, 'one'), (3, 'one'), (4, 'zero'), (5, 'zero'), (6, 'zero')] │ [(0, 'zero'), (2, 'one'), (3, 'one'), (4, 'zero'), (6, 'zero'), (7, 'one')] │ [(0, 'zero'), (1, 'one'), (3, 'one'), (4, 'zero'), (5, 'zero'), (7, 'one')] │\n",
      "╘═════════════════════════════════════════════════════════════════╧═════════════════════════════════════════════════════════════════╧═════════════════════════════════════════════════════════════════╧═════════════════════════════════════════════════════════════════════════════╧═════════════════════════════════════════════════════════════════════════════╧═════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "flip_deps_for_ones_and_zeroes = []\n",
    "mask_X = tm.l1.full_X == 1\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    col_Y = Y[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(col_Y == 1).squeeze(1)\n",
    "    X_flip_row_idxs_by_col = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    for row in range(mask_X.shape[0]):\n",
    "        for col in range(mask_X.shape[1]):\n",
    "            if (not mask_X[row,col] and row in zero_Y_idxs):\n",
    "                X_flip_row_idxs_by_col[col].append((row, 'one'))\n",
    "            elif (mask_X[row,col] and row not in zero_Y_idxs):\n",
    "                X_flip_row_idxs_by_col[col].append((row, 'zero'))\n",
    "\n",
    "    flip_deps_for_ones_and_zeroes.append(X_flip_row_idxs_by_col)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(flip_deps_for_ones_and_zeroes[0]))]\n",
    "print(tabulate(flip_deps_for_ones_and_zeroes, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤════════════╤════════════╤════════════╤════════════╤════════════╕\n",
      "│ Column 1   │ Column 2   │ Column 3   │ Column 4   │ Column 5   │ Column 6   │\n",
      "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ [6]        │ [6]        │ [2]        │ [2]        │ [2]        │ [6]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [6, 7]     │ [1, 6]     │ [2]        │ [1, 2]     │ [2, 7]     │ [1, 6, 7]  │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [4, 7]     │ [0, 1, 4]  │ [0, 4]     │ [0, 1, 3]  │ [3, 7]     │ [1, 3, 7]  │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [4, 7]     │ [0, 4]     │ [0, 4]     │ [0]        │ [7]        │ [7]        │\n",
      "├────────────┼────────────┼────────────┼────────────┼────────────┼────────────┤\n",
      "│ [7]        │ [1]        │ [2]        │ [1, 2, 3]  │ [2, 3, 7]  │ [1, 3, 7]  │\n",
      "╘════════════╧════════════╧════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "mask_X = tm.l1.full_X == 1\n",
    "flip_deps_for_ones = []\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    col_Y = Y[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(col_Y == 1).squeeze(1)\n",
    "    X_flip_row_idxs_by_col = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    for row in range(mask_X.shape[0]):\n",
    "        for col in range(mask_X.shape[1]):\n",
    "            if (not mask_X[row,col] and row in zero_Y_idxs):\n",
    "                X_flip_row_idxs_by_col[col].append(row)\n",
    "\n",
    "    flip_deps_for_ones.append(X_flip_row_idxs_by_col)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(flip_deps_for_ones[0]))]\n",
    "print(tabulate(flip_deps_for_ones, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 6], [1, 2, 6, 7], [0, 1, 3, 4, 7], [0, 4, 7], [1, 2, 3, 7]]"
      ]
     },
     "execution_count": 1466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "one_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = Y[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    one_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "one_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [2, 4, 0, 3], [3, 1, 4], [4], [1], [2]]"
      ]
     },
     "execution_count": 1467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 2, 4, 0, 2],\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]]))"
      ]
     },
     "execution_count": 1468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 9496461801973866405\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "\n",
    "def is_there_conflict(col_idx, row_idx, chosen_col_idxs):\n",
    "    neg_col_idx =  (col_idx + tm.l1.in_dim) % (tm.l1.in_dim * 2)\n",
    "    if neg_col_idx in chosen_col_idxs:\n",
    "        return len(set(one_Y_row_idxs_per_W_row[row_idx]) & set(one_Y_row_idxs_per_W_row[row_idx])) > 0\n",
    "    return False\n",
    "\n",
    "def can_col_idx_be_used(col_idx, row_idx, cannot_be_changed):\n",
    "    return col_idx in cannot_be_changed[row_idx] if row_idx in cannot_be_changed else False\n",
    "\n",
    "def func(W_collisions):\n",
    "    new_W = torch.zeros_like(tm.l1.W)\n",
    "    \n",
    "    cannot_be_changed = {}\n",
    "    for i in range(len(W_collisions)//2):\n",
    "        if len(W_collisions[i]) > 0:\n",
    "            neg_i = i + len(W_collisions)//2\n",
    "            selected_index = random.choice([i,neg_i])\n",
    "            if len(W_collisions[i]) > len(W_collisions[neg_i]):\n",
    "                selected_index = neg_i\n",
    "            elif len(W_collisions[i]) < len(W_collisions[neg_i]):\n",
    "                selected_index = i\n",
    "            \n",
    "            for row_i in W_collisions[selected_index]:\n",
    "                if row_i not in cannot_be_changed:\n",
    "                    cannot_be_changed[row_i] = []\n",
    "                cannot_be_changed[row_i].append(selected_index)\n",
    "\n",
    "    selected_col_idxs = torch.zeros(new_W.shape[0]).tolist()\n",
    "    remaining_row_idxs = [i for i in range(new_W.shape[0]) if i not in cannot_be_changed.keys()]\n",
    "    for row_idx in (sorted(list(cannot_be_changed.keys())) + remaining_row_idxs):\n",
    "        available_col_idxs = [i for i in range(new_W.shape[1])]\n",
    "        random.shuffle(available_col_idxs)\n",
    "        candidate_list_idx = 0\n",
    "        candidate_col_idx = available_col_idxs[candidate_list_idx]\n",
    "        col_idx_cannot_be_used = can_col_idx_be_used(candidate_col_idx, row_idx, cannot_be_changed)\n",
    "        while col_idx_cannot_be_used or is_there_conflict(candidate_col_idx, row_idx, selected_col_idxs):\n",
    "            candidate_list_idx += 1\n",
    "            candidate_col_idx = available_col_idxs[candidate_list_idx]\n",
    "            col_idx_cannot_be_used = can_col_idx_be_used(candidate_col_idx, row_idx, cannot_be_changed)\n",
    "\n",
    "        new_W[row_idx, candidate_col_idx] = 1\n",
    "        selected_col_idxs[row_idx] = candidate_col_idx\n",
    "            \n",
    "    return selected_col_idxs, new_W\n",
    "\n",
    "selected_W_col_idx_per_W_row, new_W = func(W_collisions)\n",
    "selected_W_col_idx_per_W_row, new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 1],\n",
       "         [0, 1, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 1, 0, 0],\n",
       "         [1, 1, 0, 1, 1, 0]]),\n",
       " tensor([[1, 0, 0, 0, 1, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 1, 1],\n",
       "         [0, 1, 0, 1, 0, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 0, 1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_full_X = torch.clone(tm.l1.full_X)\n",
    "mask_X = torch.zeros_like(new_full_X)\n",
    "for row_idx, col_indx in enumerate(selected_W_col_idx_per_W_row):\n",
    "    X_row_idxs = flip_deps_for_ones[row_idx][col_indx]\n",
    "    for X_row_idx in X_row_idxs:\n",
    "        mask_X[X_row_idx, col_indx] = 1\n",
    "        neg_index = (col_indx + tm.l1.in_dim) % (tm.l1.in_dim*2)\n",
    "        mask_X[X_row_idx, neg_index] = 1\n",
    "\n",
    "new_full_X[mask_X.bool()] = 1 - new_full_X[mask_X.bool()]\n",
    "mask_X,new_full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 1470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsetlin import TsetlinBase\n",
    "\n",
    "tb = TsetlinBase()\n",
    "y2 = tb.conjunction_mul(new_full_X.unsqueeze(1), new_W)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤════════════╤══════════════╤════════════╤═════════════════╤════════════╕\n",
      "│ Column 1        │ Column 2   │ Column 3     │ Column 4   │ Column 5        │ Column 6   │\n",
      "╞═════════════════╪════════════╪══════════════╪════════════╪═════════════════╪════════════╡\n",
      "│ [0, 1, 3, 4, 7] │ [5]        │ [1, 3, 7]    │ [5]        │ [0, 1, 3, 4, 7] │ [0, 4, 5]  │\n",
      "├─────────────────┼────────────┼──────────────┼────────────┼─────────────────┼────────────┤\n",
      "│ [0, 3, 4]       │ [5]        │ [3]          │ [5]        │ [0, 3, 4]       │ [0, 4, 5]  │\n",
      "├─────────────────┼────────────┼──────────────┼────────────┼─────────────────┼────────────┤\n",
      "│ [2, 6]          │ [2, 5]     │ [2, 6]       │ [5]        │ [6]             │ [5]        │\n",
      "├─────────────────┼────────────┼──────────────┼────────────┼─────────────────┼────────────┤\n",
      "│ [1, 2, 3, 6]    │ [2, 5]     │ [1, 2, 3, 6] │ [5]        │ [1, 3, 6]       │ [5]        │\n",
      "├─────────────────┼────────────┼──────────────┼────────────┼─────────────────┼────────────┤\n",
      "│ [0, 4, 6]       │ [5]        │ [6]          │ [5]        │ [0, 4, 6]       │ [0, 4, 5]  │\n",
      "╘═════════════════╧════════════╧══════════════╧════════════╧═════════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "mask_X = new_full_X == 1\n",
    "flip_deps_for_zeroes = []\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    col_Y = Y[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(col_Y == 0).squeeze(1)\n",
    "    X_flip_row_idxs_by_col = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    for row in range(mask_X.shape[0]):\n",
    "        for col in range(mask_X.shape[1]):\n",
    "            if (mask_X[row,col] and row in zero_Y_idxs):\n",
    "                X_flip_row_idxs_by_col[col].append(row)\n",
    "\n",
    "    flip_deps_for_zeroes.append(X_flip_row_idxs_by_col)\n",
    "\n",
    "headers = [f\"Column {i+1}\" for i in range(len(flip_deps_for_zeroes[0]))]\n",
    "print(tabulate(flip_deps_for_zeroes, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 3, 4, 5, 7], [0, 3, 4, 5], [2, 5, 6], [1, 2, 3, 5, 6], [0, 4, 5, 6]]"
      ]
     },
     "execution_count": 1472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "zero_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = Y[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 0).squeeze(1).tolist()\n",
    "    zero_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "zero_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2, 6], [1, 2, 6, 7], [0, 1, 3, 4, 7], [0, 4, 7], [1, 2, 3, 7]],\n",
       " [[0, 1, 3, 4, 5, 7], [0, 3, 4, 5], [2, 5, 6], [1, 2, 3, 5, 6], [0, 4, 5, 6]])"
      ]
     },
     "execution_count": 1473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_Y_row_idxs_per_W_row, zero_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "3158761121381184149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 1505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# SEED = 9496461801973866405 this works\n",
    "SEED = 3158761121381184149\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "tm.l1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 4, 5, 6, 7],\n",
       " [0, 1, 2, 4, 5, 6, 7],\n",
       " [0, 1, 2, 4, 5, 6, 7],\n",
       " [2, 3, 5, 7],\n",
       " [0, 1, 2, 4, 5, 6]]"
      ]
     },
     "execution_count": 1506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "zero_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = tm.l1.out[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 0).squeeze(1).tolist()\n",
    "    zero_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "zero_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [3], [3], [0, 1, 4, 6], [3, 7]]"
      ]
     },
     "execution_count": 1507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "one_Y_row_idxs_per_W_row = []\n",
    "for i in range(tm.l1.W.shape[0]):\n",
    "    row_Y = tm.l1.out[:, i]\n",
    "    zero_Y_idxs = torch.nonzero(row_Y == 1).squeeze(1).tolist()\n",
    "    one_Y_row_idxs_per_W_row.append(zero_Y_idxs)\n",
    "one_Y_row_idxs_per_W_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 0, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 1, 0, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 1, 1],\n",
       "         [1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 0, 0, 0, 1],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 1, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 1, 0],\n",
       "         [0, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 1508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.W, tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{0, 1, 4, 6}, {3, 7}]],\n",
       " {(1, 3): [0, 0, 0],\n",
       "  (3,): [-3, 0, 0],\n",
       "  (0, 1, 4, 6): [3, 0, 0],\n",
       "  (3, 7): [-3, 0, 0]},\n",
       " {(1, 3): {0, 2, 4, 5, 6, 7},\n",
       "  (3,): {2, 5, 7},\n",
       "  (0, 1, 4, 6): {2, 5},\n",
       "  (3, 7): {2, 5}})"
      ]
     },
     "execution_count": 1509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sets = [set(x) for x in one_Y_row_idxs_per_W_row]\n",
    "zero_sets = [set(x) for x in zero_Y_row_idxs_per_W_row]\n",
    "tracking = {tuple(x):y for x, y in zip(one_sets, zero_sets)}\n",
    "solution = {tuple(x):[0,0,0] for x in one_sets}\n",
    "\n",
    "cols = []\n",
    "for i in range(tm.l1.in_dim):\n",
    "    one_sets = []\n",
    "    zero_sets = []\n",
    "    for k,v in tracking.items():\n",
    "        one_sets.append(set(k))\n",
    "        zero_sets.append(v)\n",
    "\n",
    "    one_sets_occurrence_in_zeros = {tuple(x):[] for x in one_sets}\n",
    "\n",
    "    for x in one_sets:\n",
    "        for i, y in enumerate(zero_sets):\n",
    "            if x.issubset(y):\n",
    "                one_sets_occurrence_in_zeros[tuple(x)].append(i)\n",
    "\n",
    "    max_occurrence_term = None\n",
    "    max_occurrence_count = None\n",
    "    count_dict = {k: len(v) for k,v in one_sets_occurrence_in_zeros.items()}\n",
    "    for k,v in count_dict.items():\n",
    "        if max_occurrence_term is None or v > max_occurrence_count:\n",
    "            max_occurrence_count = v\n",
    "            max_occurrence_term = k\n",
    "        elif v == max_occurrence_count and len(k) > len(max_occurrence_term):\n",
    "            max_occurrence_count = v\n",
    "            max_occurrence_term = k\n",
    "\n",
    "    one_rows = set(max_occurrence_term)\n",
    "    corresponding_zeroes = tracking[max_occurrence_term]\n",
    "    zero_rows = set().union(*[ x for i, x in enumerate(one_sets) if i in one_sets_occurrence_in_zeros[max_occurrence_term]])\n",
    "    \n",
    "    match_col = -1\n",
    "    match_one_rows_side = None\n",
    "    max_zero_rows_intersection = -1\n",
    "    for i, col in enumerate(cols):\n",
    "        # TODO: it doesnt have to be an exact subset, but something that could be made into a subset\n",
    "        if one_rows.issubset(col[0]) and len(corresponding_zeroes & col[0]) == 0:\n",
    "            if match_col == -1 or len(zero_rows & col[1]) > max_zero_rows_intersection:\n",
    "                match_col = i\n",
    "                max_zero_rows_intersection = len(zero_rows & col[1])\n",
    "                match_one_rows_side = 0\n",
    "        # elif one_rows.issubset(col[1]) and len(corresponding_zeroes & col[1]) == 0:\n",
    "        #     if match_col == -1 or len(zero_rows & col[0]) > max_zero_rows_intersection:\n",
    "        #         match_col = i\n",
    "        #         max_zero_rows_intersection = len(zero_rows & col[0])\n",
    "        #         match_one_rows_side = 1\n",
    "\n",
    "    if match_col == -1:\n",
    "        all_zero_rows = zero_rows\n",
    "        to_add = [one_rows, all_zero_rows]\n",
    "        left_side = one_rows\n",
    "        right_side = all_zero_rows\n",
    "        cols.append(to_add)\n",
    "        match_col = len(cols) - 1\n",
    "        match_one_rows_side = 0\n",
    "    else:\n",
    "        found_col = cols[match_col]\n",
    "        # combined_zeroes = corresponding_zeroes | zero_rows\n",
    "        allowed_zeroes = zero_rows - found_col[match_one_rows_side]\n",
    "\n",
    "        all_zero_rows = found_col[1- match_one_rows_side] | allowed_zeroes\n",
    "        found_col[1- match_one_rows_side] = all_zero_rows\n",
    "\n",
    "        left_side = found_col[0]\n",
    "        right_size = found_col[1]\n",
    "        \n",
    "    remove_ks = []\n",
    "    for k,v in tracking.items():\n",
    "        k_set = set(k)\n",
    "        if k_set.issubset(left_side):\n",
    "            sub = v - right_side\n",
    "            if len(sub) > 0:\n",
    "                tracking[k] = sub\n",
    "                solution[tuple(k_set)][match_col] += 1\n",
    "            else:\n",
    "                remove_ks.append(k)\n",
    "                solution[tuple(k_set)][match_col] += 1\n",
    "        elif k_set.issubset(right_side):\n",
    "            sub = v - left_side\n",
    "            if len(sub) > 0:\n",
    "                solution[tuple(k_set)][match_col] -= 1\n",
    "                tracking[k] = sub\n",
    "            else:\n",
    "                remove_ks.append(k)\n",
    "                solution[tuple(k_set)][match_col] -= 1\n",
    "    for k in remove_ks:\n",
    "        tracking.pop(k)\n",
    "\n",
    "cols, solution, tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{0, 1, 2, 4, 5, 6}, {3, 7}]],\n",
       " {(1, 3): {0, 2, 4, 5, 6, 7}, (3,): {7}, (0, 1, 4, 6): {2, 5}},\n",
       " {(1, 3): [0, 0, 0],\n",
       "  (3,): [-3, 0, 0],\n",
       "  (0, 1, 4, 6): [3, 0, 0],\n",
       "  (3, 7): [-3, 0, 0]})"
      ]
     },
     "execution_count": 1510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_row_to_col_idxs = {}\n",
    "available_rows_per_col = []\n",
    "for col in cols:\n",
    "    all_rows = col[0] | col[1]\n",
    "    remaining_rows = set(range(tm.l1.full_X.shape[0])) - all_rows\n",
    "    available_rows_per_col.append(remaining_rows)\n",
    "\n",
    "\n",
    "for x in one_Y_row_idxs_per_W_row:\n",
    "    for i, col in enumerate(cols):\n",
    "        if set(x).issubset(col[0]):\n",
    "            if tuple(x) not in one_row_to_col_idxs:\n",
    "                one_row_to_col_idxs[tuple(x)] = []\n",
    "            one_row_to_col_idxs[tuple(x)].append((i,0))\n",
    "\n",
    "        elif set(x).issubset(col[1]):\n",
    "            if tuple(x) not in one_row_to_col_idxs:\n",
    "                one_row_to_col_idxs[tuple(x)] = []\n",
    "            one_row_to_col_idxs[tuple(x)].append((i,1))\n",
    "\n",
    "col_idxs_to_one_rows = {}\n",
    "for k,v in one_row_to_col_idxs.items():\n",
    "    for col_idx in v:\n",
    "        if col_idx not in col_idxs_to_one_rows:\n",
    "            col_idxs_to_one_rows[col_idx] = []\n",
    "        col_idxs_to_one_rows[col_idx].append(k)\n",
    "\n",
    "sorted_keys = sorted(col_idxs_to_one_rows, key=lambda x: len(col_idxs_to_one_rows[x]), reverse=True)\n",
    "for key in sorted_keys:\n",
    "    one_rows = [x for x in col_idxs_to_one_rows[key] if x in tracking]\n",
    "    if one_rows:\n",
    "\n",
    "        intersect = set(range(tm.l1.full_X.shape[0])).intersection(*[tracking[x] for x in one_rows])\n",
    "        intersect_with_available = intersect & available_rows_per_col[key[0]]\n",
    "\n",
    "        available_rows_per_col[key[0]] -= intersect_with_available\n",
    "        col_part = cols[key[0]][1-key[1]]\n",
    "        col_part |= intersect_with_available\n",
    "        remove_ks = []\n",
    "        for k,v in tracking.items():\n",
    "            if k in one_rows:\n",
    "                sub = v - intersect_with_available\n",
    "                if len(sub) > 0:\n",
    "                    tracking[k] = sub\n",
    "                else:\n",
    "                    remove_ks.append(k)\n",
    "\n",
    "        for k in remove_ks:\n",
    "            tracking.pop(k)\n",
    "\n",
    "remove_ks = []\n",
    "for k,v in tracking.items():\n",
    "    for i, col in enumerate(cols):\n",
    "        col_remaining_size = tm.l1.full_X.shape[0]-(len(col[0]) + len(col[1]))\n",
    "        if len(k) <= col_remaining_size:\n",
    "            if not set(k).issubset(col[0]) and len(v & col[0]) == 0:\n",
    "                col[0] |= set(k)\n",
    "                col_remaining_size -= len(k)\n",
    "                remaining_v = list(v - col[1])\n",
    "                remaining_to_add = remaining_v[:min(col_remaining_size, len(remaining_v))]\n",
    "                remaining_v_size = len(remaining_v) - col_remaining_size\n",
    "                col[1] |= set(remaining_to_add)\n",
    "                if remaining_v_size > 0:\n",
    "                    tracking[k] = sub\n",
    "                    solution[k][i] += 1\n",
    "                else:\n",
    "                    remove_ks.append(k)\n",
    "                    solution[k][i] += 1\n",
    "                break\n",
    "            elif not set(k).issubset(col[1]) and len(v & col[1]) == 0:\n",
    "                col[1] |= set(k)\n",
    "                col_remaining_size -= len(k)\n",
    "                remaining_v = list(v - col[0])\n",
    "                remaining_to_add = remaining_v[:min(col_remaining_size, len(remaining_v))]\n",
    "                remaining_v_size = len(remaining_v) - col_remaining_size\n",
    "                col[0] |= set(remaining_to_add)\n",
    "                if remaining_v_size > 0:\n",
    "                    tracking[k] = sub\n",
    "                    solution[k][i] -= 1\n",
    "                else:\n",
    "                    remove_ks.append(k)\n",
    "                    solution[k][i] -= 1\n",
    "                break\n",
    "for k in remove_ks:\n",
    "    tracking.pop(k)\n",
    "cols, tracking, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0, 1, 2, 4, 5, 6}, {3, 7}]]"
      ]
     },
     "execution_count": 1511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cols:\n",
    "    remaining_rows = set(range(tm.l1.full_X.shape[0])) - (col[0] | col[1])\n",
    "    col[1] |= remaining_rows\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 1512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_full_X = torch.zeros_like(tm.l1.full_X)\n",
    "for i, col in enumerate(cols):\n",
    "    new_full_X[list(col[0]), i] = 1\n",
    "    new_full_X[list(col[1]), i + tm.l1.in_dim] = 1\n",
    "new_full_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 1513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_W = torch.zeros_like(tm.l1.W)\n",
    "for i, x in enumerate(one_Y_row_idxs_per_W_row):\n",
    "    W_row_values = solution[tuple(x)]\n",
    "    for j, val in enumerate(W_row_values):\n",
    "        if val > 0:\n",
    "            new_W[i, j] = 1\n",
    "        elif val < 0:\n",
    "            new_W[i, j + tm.l1.in_dim] = 1\n",
    "new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 1514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsetlin import TsetlinBase\n",
    "\n",
    "tb = TsetlinBase()\n",
    "y2 = tb.conjunction_mul(new_full_X.unsqueeze(1), new_W)\n",
    "y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
