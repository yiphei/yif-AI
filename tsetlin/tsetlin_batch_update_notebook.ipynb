{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "from tsetlin import TsetlinMachine\n",
    "import torch\n",
    "import random\n",
    "\n",
    "DATASET_DIR = '../datasets/'\n",
    "DATA_FILE = 'bit_1.txt'\n",
    "SEED = 17648192976567996066\n",
    "\n",
    "text_rows = open(f'{DATASET_DIR}{DATA_FILE}', 'r').read().splitlines()\n",
    "dataset = [ [int(num) for num in row.split(',')] for row in text_rows]\n",
    "tensor_dataset = torch.tensor(dataset)\n",
    "train_x = tensor_dataset[:, :-1]\n",
    "train_y = tensor_dataset[:, -1]\n",
    "\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "else:\n",
    "    seed = int.from_bytes(os.urandom(8), byteorder=\"big\", signed=False)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(seed)\n",
    "tm = TsetlinMachine(train_x.shape[1], 5)\n",
    "out_1 = tm.forward(train_x)\n",
    "out_1, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 1, 1, 0, 1],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1]]),\n",
       " tensor([[0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 1]]),\n",
       " tensor([[0, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.randint(0,2, tm.l1.out.size())\n",
    "tm.l1.out, Y, tm.l1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], [], [], []],\n",
       " [[2], [], [], [3], [], []],\n",
       " [[1, 2], [1, 2], [], [3], [0], []],\n",
       " [[2], [2], [], [3], [0], []],\n",
       " [[], [], [], [], [], []],\n",
       " [[], [], [], [], [], []],\n",
       " [[1, 2], [1, 2], [], [3], [0], []],\n",
       " [[], [1, 2], [], [], [0], []]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_deps = []\n",
    "for i, single_x in enumerate(tm.l1.full_X):\n",
    "    flip_dep_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "    single_Y = Y[i]\n",
    "    one_Y_idxs = torch.nonzero(single_Y == 1).squeeze(1)\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in one_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        for neg_one_Y_idx in one_Y_idxs:\n",
    "            w_2 = neg_W[neg_one_Y_idx]\n",
    "            deps = ((w_1 == w_2) & (w_1 == 1))\n",
    "            if deps.any():\n",
    "                dep_idxs = deps.nonzero(as_tuple=True)[0]\n",
    "                for idx in dep_idxs:\n",
    "                    if pos_one_Y_idx.item() not in flip_dep_row[idx]:\n",
    "                        flip_dep_row[idx].append(pos_one_Y_idx.item())\n",
    "                    if neg_one_Y_idx.item() not in flip_dep_row[idx + tm.l1.in_dim]:\n",
    "                        flip_dep_row[idx + tm.l1.in_dim].append(neg_one_Y_idx.item())\n",
    "    flip_deps.append(flip_dep_row)\n",
    "flip_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], [], [], []],\n",
       " [[2], [2], [2], [3], [], []],\n",
       " [[1, 2], [1, 2], [0, 1, 2], [3], [0], []],\n",
       " [[2], [2], [0, 2, 4], [3], [0], []],\n",
       " [[], [], [4], [3], [], []],\n",
       " [[], [], [], [3], [], []],\n",
       " [[1, 2], [1, 2], [0, 1, 2, 4], [3], [0], []],\n",
       " [[1, 2], [1, 2], [0, 1, 2, 4], [], [0], []]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_deps_full = []\n",
    "for i, single_x in enumerate(tm.l1.full_X):\n",
    "    flip_dep_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "    single_Y = Y[i]\n",
    "    one_Y_idxs = torch.nonzero(single_Y == 1).squeeze(1)\n",
    "    W_halves = torch.split(tm.l1.W, tm.l1.in_dim, dim=1)\n",
    "    pos_W = W_halves[0]\n",
    "    neg_W = W_halves[1]\n",
    "    for pos_one_Y_idx in one_Y_idxs:\n",
    "        w_1 = pos_W[pos_one_Y_idx]\n",
    "        for neg_one_Y_idx in one_Y_idxs:\n",
    "            w_2 = neg_W[neg_one_Y_idx]\n",
    "            pos_one_W_idxs = torch.nonzero(w_1 == 1).squeeze(1)\n",
    "            neg_one_W_idxs = torch.nonzero(w_2 == 1).squeeze(1)\n",
    "            for idx in pos_one_W_idxs:\n",
    "                if pos_one_Y_idx.item() not in flip_dep_row[idx.item()]:\n",
    "                    flip_dep_row[idx.item()].append(pos_one_Y_idx.item())\n",
    "            for idx in neg_one_W_idxs:\n",
    "                if neg_one_Y_idx.item() not in flip_dep_row[idx.item() + tm.l1.in_dim]:\n",
    "                    flip_dep_row[idx.item() + tm.l1.in_dim].append(neg_one_Y_idx.item())\n",
    "            # deps = ((w_1 == w_2) & (w_1 == 1))\n",
    "            # if deps.any():\n",
    "            #     dep_idxs = deps.nonzero(as_tuple=True)[0]\n",
    "            #     for idx in dep_idxs:\n",
    "            #         if pos_one_Y_idx.item() not in flip_dep_row[idx]:\n",
    "            #             flip_dep_row[idx].append(pos_one_Y_idx.item())\n",
    "            #         if neg_one_Y_idx.item() not in flip_dep_row[idx + tm.l1.in_dim]:\n",
    "            #             flip_dep_row[idx + tm.l1.in_dim].append(neg_one_Y_idx.item())\n",
    "    flip_deps_full.append(flip_dep_row)\n",
    "flip_deps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.l1.full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 2, 3, 4, 5],\n",
       "  [[6, 7, 0, 1],\n",
       "   [6, 5],\n",
       "   [2, 1],\n",
       "   [2, 3, 4, 5],\n",
       "   [2, 3, 7, 0, 1, 4],\n",
       "   [3, 6, 7, 0, 4, 5]]],\n",
       " [[0, 1, 2, 3, 4, 5],\n",
       "  [[6, 7, 0, 1, 3],\n",
       "   [6, 3, 5],\n",
       "   [2, 1, 3],\n",
       "   [2, 4, 5],\n",
       "   [2, 7, 0, 1, 4],\n",
       "   [6, 7, 0, 4, 5]]],\n",
       " [[0, 1, 2, 3, 4, 5],\n",
       "  [[6, 7, 0],\n",
       "   [1, 6, 5],\n",
       "   [2],\n",
       "   [1, 2, 3, 4, 5],\n",
       "   [2, 3, 7, 0, 4],\n",
       "   [1, 3, 6, 7, 0, 4, 5]]],\n",
       " [[0, 1, 2, 3, 4, 5],\n",
       "  [[4, 5, 6, 0],\n",
       "   [1, 4, 6, 7],\n",
       "   [2, 4, 5, 7],\n",
       "   [1, 2, 3, 7],\n",
       "   [2, 3, 5, 0],\n",
       "   [1, 3, 6, 0]]],\n",
       " [[0, 1, 2, 3, 4, 5],\n",
       "  [[4, 6, 7, 0, 1, 2],\n",
       "   [4, 6, 2, 5],\n",
       "   [4, 1],\n",
       "   [3, 5],\n",
       "   [3, 7, 0, 1],\n",
       "   [3, 6, 7, 0, 2, 5]]]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_deps = []\n",
    "for i, single_W in enumerate(tm.l1.W):\n",
    "    single_Y = Y[:, i]\n",
    "    single_out = tm.l1.out[:, i]\n",
    "    one_Y_idxs = torch.nonzero(single_Y == 1).squeeze(1)\n",
    "    x_prod = tm.l1.full_X[one_Y_idxs].prod(dim=0)    \n",
    "    must_be_one_idxs = torch.nonzero(x_prod == 1).squeeze(1)\n",
    "    zero_Y_idxs = torch.nonzero(single_Y == 0).squeeze(1)\n",
    "    must_be_flipped_row = [[] for _ in range(tm.l1.in_dim * 2)]\n",
    "\n",
    "    if len(must_be_one_idxs) == 0:\n",
    "        must_be_one_idxs = torch.arange(tm.l1.in_dim * 2)\n",
    "\n",
    "        x_stuff = tm.l1.full_X[one_Y_idxs] == 0\n",
    "        for row in range(x_stuff.shape[0]):\n",
    "            for col in range(x_stuff.shape[1]):\n",
    "                if x_stuff[row, col]:\n",
    "                    must_be_flipped_row[col].append(one_Y_idxs[row].item())\n",
    "\n",
    "\n",
    "    x_stuff = tm.l1.full_X[zero_Y_idxs][:, must_be_one_idxs] == 1\n",
    "    for row in range(x_stuff.shape[0]):\n",
    "        for col in range(x_stuff.shape[1]):\n",
    "            if x_stuff[row, col] and zero_Y_idxs[row].item() not in must_be_flipped_row[must_be_one_idxs[col]]:\n",
    "                must_be_flipped_row[must_be_one_idxs[col]].append(zero_Y_idxs[row].item())\n",
    "\n",
    "\n",
    "    W_deps.append([must_be_one_idxs.tolist(), must_be_flipped_row])\n",
    "\n",
    "W_deps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd-yifei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
