{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, DistributedSampler\n",
    "from torchdata.datapipes.iter import Shuffler\n",
    "\n",
    "class LocalDataset(IterableDataset):\n",
    "    def __init__(self, file_path, context_size):\n",
    "        self.data = np.memmap(file_path, dtype=np.uint16, mode=\"r\")\n",
    "        self.context_size = context_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.context_size - 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        sampler = DistributedSampler(self, num_replicas=1, rank=0, shuffle=False)\n",
    "        sampler_iter = iter(sampler)\n",
    "        next_sample = next(sampler_iter)\n",
    "        for idx in range(len(self.data) - self.context_size - 1):\n",
    "            if idx == next_sample:\n",
    "                next_sample = next(sampler_iter)\n",
    "                x = torch.from_numpy(\n",
    "                    (self.data[idx : idx + self.context_size]).astype(np.int64)\n",
    "                )\n",
    "                y = torch.from_numpy(\n",
    "                    (self.data[idx + 1 : idx + self.context_size + 1]).astype(np.int64)\n",
    "                )\n",
    "                yield x, y\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "class ParallelDataset(IterableDataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        sampler = DistributedSampler(self.dataset, num_replicas=1, rank=0, shuffle=False)\n",
    "        for sample in iter(sampler), iter(self.dataset):\n",
    "            yield sample\n",
    "\n",
    "\n",
    "path = '/Users/yifeiyan/yif-AI/datasets/full_harry_potter/full_harry_potter_train.bin'\n",
    "context_size = 5\n",
    "dataset = LocalDataset(path, context_size)\n",
    "parallel_dataset = ParallelDataset(dataset)\n",
    "parallel_dataset = Shuffler(parallel_dataset, buffer_size=2)\n",
    "loader = DataLoader(parallel_dataset, batch_size=5, num_workers=0)\n",
    "a = iter(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
