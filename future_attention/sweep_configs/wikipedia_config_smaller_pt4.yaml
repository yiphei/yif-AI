program: future_attention_transformer/training_script.py
name: testtt_wikipedia_config_smaller_pt4_cosine
project: future_attention_transformer_v1
method: grid
metric:
  goal: minimize
  name: est_val_loss
parameters:
    model_config:
        parameters:
            use_bias:
                value: False
            context_size:
                value: 10
            n_embed: 
                value: 10
            n_layer: 
                value: 1
            n_head: 
                value: 2
            dropout_rate:
                value: 0
            start_layer:
                value: 1
            end_layer:
                value: 1
            future_attn_loss_type:
                values: [1, 2]
            use_future_attn_loss:
                value: True
            future_dim:
                values: [2, 3]
            detach_future_ground_truth:
                value: True
            future_attn_loss_coeff:
                value: 1
    batch_size: 
        value: 10
    train_steps: 
        value: 500
    lr: 
        value: 9e-4
    warmup_iters:
        value: 200
    min_lr: 
        value: 9e-5
    gradient_accumulation_steps: 
        value: 16
    lr_decay_iters: 
        value: 700000
    est_interval: 
        value: 200
    est_steps: 
        value: 100