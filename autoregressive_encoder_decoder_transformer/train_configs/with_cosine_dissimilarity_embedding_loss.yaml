lr: 0.0009
beta1: 0.9
beta2: 0.95
min_lr: 9.0e-05
decay_lr: true
est_steps: 200
batch_size: 50
train_steps: 9000
est_interval: 500
model_config:
  n_head: 5
  n_embed: 150
  n_layer: 13
  use_bias: false
  order_type: 1
  context_size: 200
  dropout_rate: 0
  cross_attn_config:
    n_head: 10
    use_bias: false
  embedding_ln_type: 2
  use_ln_on_encoder_out: true
  embedding_loss_type: 3
  add_ln_before_decoder_ff: false
  add_pos_embed_to_decoder: false
  embedding_loss_coeff: 1
  sub_pos_embed_to_decoder: 1
  detach_type: 3
warmup_iters: 300
weight_decay: 0.1
lr_decay_iters: 700000
gradient_accumulation_steps: 16